#

# Research Paper: REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

# REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

Authors: Shunyu Yao*, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao

Affiliations: 1Department of Computer Science, Princeton University 2Google Research, Brain team

Contact: 2{jeffreyzhao, dianyu, dunan, izhak, yuancao}@google.com 1{shunyuy, karthikn}@princeton.edu

# ABSTRACT

Large language models (LLMs) have shown impressive performance in language understanding and decision making tasks. This paper introduces ReAct, a method that combines reasoning traces and task-specific actions in LLMs to enhance their performance across various tasks. ReAct demonstrates effectiveness in question answering, fact verification, and interactive decision making tasks, outperforming existing baselines.

# 1 INTRODUCTION

The paper discusses the importance of combining verbal reasoning with task-oriented actions in human intelligence. It highlights the synergy between acting and reasoning in enabling efficient decision making and task performance. The potential of integrating verbal reasoning with interactive decision making in autonomous systems is also explored.

Key Points:

- Humans combine verbal reasoning with task-oriented actions for efficient task performance.
- Large language models show capabilities in reasoning and decision making.
- ReAct method enhances LLM performance in various tasks.

Published as a conference paper at ICLR 2023
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Table of Contents

1. Introduction
2. Comparison of Prompting Methods
3. Combining Reasoning and Acting with Language Models

# Figure 1: Comparison of Prompting Methods

(1) Comparison of 4 prompting methods, (a) Standard, (b) Chain-of-thought (CoT, Reason Only), (c) Act-only, and (d) ReAct (Reason+Act), solving a HotpotQA (Yang et al., 2018) question. (2) Comparison of (a) Act-only and (b) ReAct prompting to solve an AlfWorld (Shridhar et al., 2020b) game. In both domains, we omit in-context examples in the prompt, and only show task solving trajectories generated by the model (Act, Thought) and the environment (Obs).

# Abstract

The research paper discusses the challenges of reasoning and acting in language models, highlighting the limitations of existing methods and introducing ReAct as a novel approach to combine reasoning and acting for improved task solving.

# Conclusion

ReAct presents a promising direction for enhancing the capabilities of language models in handling complex tasks that require both reasoning and acting components. Further research and experimentation are needed to fully explore the potential benefits of this synergistic approach.

# References

- Yang et al., 2018 - HotpotQA
- Shridhar et al., 2020b - AlfWorld
- Wei et al., 2022 - Multi-modal reasoning tasks
- Ahn et al., 2022; Nakano et al., 2021; Yao et al., 2020; Huang et al., 2022a - Pre-trained language models for planning and acting
- Huang et al., 2022b - Verbal reasoning in interactive environments
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

Published as a conference paper at ICLR 2023

We conduct empirical evaluations of ReAct and state-of-the-art baselines on four diverse benchmarks: question answering (HotPotQA, Yang et al., 2018), fact verification (Fever, Thorne et al., 2018), text-based game (ALFWorld, Shridhar et al., 2020b), and webpage navigation (WebShop, Yao et al., 2022). For HotPotQA and Fever, with access to a Wikipedia API that the model can interact with, ReAct outperforms vanilla action generation models while being competitive with chain-of-thought reasoning (CoT) (Wei et al., 2022). The best approach overall is a combination of ReAct and CoT that allows for the use of both internal knowledge and externally obtained information during reasoning. On ALFWorld and WebShop, two or even one-shot ReAct prompting is able to outperform imitation or reinforcement learning methods trained with 103 ∼ 105 task instances, with an absolute improvement of 34% and 10% in success rates respectively. We also demonstrate the importance of sparse, versatile reasoning in decision making by showing consistent advantages over controlled baselines with actions only. Besides general applicability and performance boost, the combination of reasoning and acting also contributes to model interpretability, trustworthiness, and diagnosability across all domains, as humans can readily distinguish information from the model’s internal knowledge versus external environments, as well as inspect reasoning traces to understand the decision basis of model actions.

To summarize, our key contributions are the following:
1. We introduce ReAct, a novel prompt-based paradigm to synergize reasoning and acting in language models for general task solving.
2. We perform extensive experiments across diverse benchmarks to showcase the advantage of ReAct in a few-shot learning setup over prior approaches that perform either reasoning or action generation in isolation.
3. We present systematic ablations and analysis to understand the importance of acting in reasoning tasks, and reasoning in interactive tasks.
4. We analyze the limitations of ReAct under the prompting setup (i.e. limited support of reasoning and acting behaviors), and perform initial fine-tuning experiments showing the potential of ReAct to improve with additional training data. Scaling up ReAct to train and operate on more tasks and combining it with complementary paradigms like reinforcement learning could further unlock the potential of large language models.

# REAC T: SYNERGIZING REASONING + ACTING

Consider a general setup of an agent interacting with an environment for task solving. At time step t, an agent receives an observation ot ∈ O from the environment and takes an action at ∈ A following some policy π(a|ct), where ct = (o1, a1, · · · , ot−1, at−1, ot) is the context to the agent. Learning a policy is challenging when the mapping ct 7→ at is highly implicit and requires extensive computation. For example, the agent shown in Figure 1(1c) is unable to generate the correct final action (Act 4) to finish the QA task as it requires complex reasoning over the trajectory context (Question, Act 1-3, Obs 1-3). Similarly, the agent shown in Figure 1(2a) fails to comprehend from the context that sinkbasin 1 does not contain peppershaker 1, thus keep producing hallucinating actions.

The idea of ReAct is simple: we augment the agent’s action space to ˆ = A ∪ L, where L is the space of language. An action ˆt ∈ L in the language space, which we will refer to as a thought or a reasoning trace, does not affect the external environment, thus leading to no observation feedback. Instead, a thought ˆt aims to compose useful information by reasoning over the current context ct,a and update the context ct+1 = (ct, ˆt) to support future reasoning or acting. As shown in Figure 1, there could be various types of useful thoughts, e.g. decomposing task goals and create action plans (2b, Act 1; 1d, Thought 1), injecting commonsense knowledge relevant to task solving (2b, Act 1), extracting important parts from observations (1d, Thought2, 4), track progress and transit action plans (2b, Act 8), handle exceptions and adjust action plans (1d, Thought 3), and so on.

However, as the language space L is unlimited, learning in this augmented action space is difficult and requires strong language priors. In this paper, we mainly focus on the setup where a frozen large language model, PaLM-540B (Chowdhery et al., 2022), is prompted with few-shot in-context examples to generate both domain-specific actions and free-form language thoughts for task solving. Each in-context example is a human trajectory of actions, thoughts, and environment observations to solve a task instance. For the tasks where reasoning is of primary importance, we alternate the generation of thoughts and actions so that the task-solving trajectory consists of multiple thought-action-observation steps. In contrast, for decision-making tasks that potentially involve a large number of actions, thoughts only need to be generated.
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# 3 KNOWLEDGE-INTENSIVE REASONING TASKS

We begin with knowledge-intensive reasoning tasks like multi-hop question answering and fact verification. By interacting with a Wikipedia API, ReAct is able to retrieve information to support reasoning, while also using reasoning to target what to retrieve next, demonstrating a synergy of reasoning and acting.

# 3.1 SETUP

Domains: We consider two datasets challenging knowledge retrieval and reasoning: HotPotQA and FEVER. In this work, we operate in a question-only setup for both tasks, relying on internal knowledge or interacting with an external environment to support reasoning.

Action Space: We design a simple Wikipedia web API with three types of actions for interactive information retrieval: search[entity], lookup[string], and finish[answer]. This action space simulates human interaction with Wikipedia, forcing models to retrieve via explicit reasoning in language.

# 3.2 METHODS

ReAct Prompting: For HotpotQA and Fever, we randomly select cases from the training set and compose ReAct-format trajectories as few-shot exemplars in the prompts. Each trajectory consists of multiple thought-action-observation steps, using free-form thoughts for various purposes such as decomposing questions, extracting information, performing commonsense or arithmetic reasoning.

# Tables and Figures:

Figure 1(1d): Interaction with Wikipedia API

**Table 1: Datasets for Knowledge-Intensive Reasoning Tasks**
|Dataset|Description|
|---|---|
|HotPotQA|Multi-hop question answering benchmark|
|FEVER|Fact verification benchmark|

Figure 5: Human-aligned and controllable decision-making process
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Table 1: PaLM-540B prompting results on HotpotQA and Fever

|Method|HotpotQA (EM)|Fever (Acc)|
|---|---|---|
|Standard|28.7|57.1|
|CoT (Wei et al., 2022)|29.4|56.3|
|CoT-SC (Wang et al., 2022a)|33.4|60.4|
|Act|25.7|58.9|
|ReAct|27.4|60.9|
|CoT-SC → ReAct|34.2|64.6|
|ReAct → CoT-SC|35.1|62.0|
|Supervised SoTAb|67.5|89.5|

# Figure 2: PaLM-540B prompting results with respect to number of CoT-SC samples used

aHotpotQA EM is 27.1, 28.9, 33.8 for Standard, CoT, CoT-SC in Wang et al. (2022b). b(Zhu et al., 2021; Lewis et al., 2020)

# Baselines

We systematically ablate ReAct trajectories to build prompts for multiple baselines:

- (a) Standard prompting (Standard)
- (b) Chain-of-thought prompting (CoT) (Wei et al., 2022)
- (c) Acting-only prompt (Act)

# Combining Internal and External Knowledge

As detailed in Section 3.3, we observe the problem-solving process demonstrated by ReAct is more factual and grounded, whereas CoT is more accurate in formulating reasoning structure but can easily suffer from hallucinated facts or thoughts.

# Finetuning

Due to the challenge of manually annotating reasoning traces and actions at scale, a bootstraping approach similar to Zelikman et al. (2022) is considered for finetuning smaller language models (PaLM-8/62B).

# RESULTS AND OBSERVATIONS

ReAct outperforms Act consistently. Fine-tuning results also confirm the benefit of reasoning traces for more informed acting.
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Types of Success and Failure Modes

|Type|Definition|ReAct|CoT|
|---|---|---|---|
|Success|True positive|Correct reasoning trace and facts|94%|86%|
| |False positive|Hallucinated reasoning trace or facts|6%|14%|
| |Reasoning error|Wrong reasoning trace (including failing to recover from repetitive steps)|47%|16%|
|Failure|Search result error|Search return empty or does not contain useful information|23%|-|
| |Hallucination|Hallucinated reasoning trace or facts|0%|56%|
| |Label ambiguity|Right prediction but did not match the label precisely|29%|28%|

# Comparison: ReAct vs. CoT

On the other hand, ReAct outperforms CoT on Fever (60.9 vs. 56.3) and slightly lags behind CoT on HotpotQA (27.4 vs. 29.4).

# ReAct + CoT-SC Performance

ReAct + CoT-SC perform best for prompting LLMs. The best prompting method on HotpotQA and Fever are ReAct → CoT-SC and CoT-SC → ReAct respectively.

# Scaling Effect of Prompting/Finetuning

Figure 3 shows the scaling effect of prompting/finetuning. ReAct performs best for finetuning on HotpotQA. With PaLM-8/62B, prompting ReAct four methods (Standard, CoT, Act) performs worst among four methods due to the difficulty to learn both reasoning and acting from in-context examples.
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Scaling Results on HotPotQA

Figure 3 shows the scaling results for prompting and finetuning on HotPotQA with ReAct (ours) and baselines.

# Decision Making Tasks

We tested ReAct on two language-based interactive decision-making tasks: ALFWorld and WebShop.

# ALFWorld

ALFWorld is a synthetic text-based game designed for complex environments that require agents to act over long horizons with sparse rewards. It challenges agents to plan, track subgoals, and explore systematically. ReAct prompts include sparse thoughts for reasoning and acting effectively in the environment.

# WebShop

WebShop is an online shopping website environment with real-world products and human instructions. ReAct prompts involve reasoning to determine exploration strategies, purchase timing, and relevant product options based on user instructions.

# Example Prompt for WebShop:

|Action|Reasoning|
|---|---|
|Search|Determine what to explore|
|Choose product|When to buy|
|Choose options|Relevant product options|
|Buy| |

For more details and model predictions, refer to the complete research paper.
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Table 3: AlfWorld task-specific success rates (%)

|Method|Pick|Clean|Heat|Cool|Look|Pick 2|All|Method|Score|SR|
|---|---|---|---|---|---|---|---|---|---|---|
|Act (best of 6)|88|42|74|67|72|41|45|Act|62.3|30.1|
|ReAct (avg)|65|39|83|76|55|24|57|ReAct|66.6|40.0|
|ReAct (best of 6)|92|58|96|86|78|41|71|IL|59.9|29.1|
|ReAct-IM (avg)|55|59|60|55|23|24|48|IL+RL|62.4|28.7|
|ReAct-IM (best of 6)|62|68|87|57|39|33|53|Human| | |
|BUTLERg (best of 8)|33|26|70|76|17|12|22|Expert|82.1|59.6|
|BUTLER (best of 8)|46|39|74|100|22|24|37| | | |

# Results

ReAct outperforms Act on both ALFWorld and Webshop. On ALFWorld, the best ReAct trial achieves an average success rate of 71%, significantly outperforming the best Act (45%) and BUTLER (37%) trials. The advantage of ReAct over Act is consistent across six controlled trials, with relative performance gain ranging from 33% to 90% and averaging 62%. Qualitatively, Act fails to correctly decompose goals into smaller subgoals or loses track of the current state of the environment. On Webshop, ReAct achieves significantly better performance with an absolute 10% improvement over the previous best success rate.

# On the value of internal reasoning vs. external feedback

ReAct is the first demonstration of combined reasoning and action using an LLM applied to an interactive environment within a closed-loop system. Ablation experiments show that ReAct substantially outperforms IM-style prompting (ReAct-IM) with consistent advantages on five out of six tasks. ReAct's reasoning traces for decision making are flexible and sparse, allowing diverse reasoning types to be induced for different tasks.
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks, we show that ReAct leads to superior performance with interpretable decision traces.

# RELATED WORK

Language model for reasoning: The work on using Large Language Models (LLMs) for reasoning has evolved significantly. Chain-of-Thought (CoT) demonstrated the ability of LLMs to formulate their own "thinking procedure" for problem-solving. Several follow-up works have explored different aspects of reasoning, such as least-to-most prompting, zero-shot-CoT, and reasoning with self-consistency. Other approaches like Selection-Inference, STaR, and Faithful reasoning have further advanced reasoning architectures. In contrast, ReAct integrates reasoning and model actions for more accurate task handling beyond reasoning.

Language model for decision making: LLMs have shown strong capabilities in decision-making tasks beyond language generation. While models like WebGPT, BlenderBot, and Sparrow utilize LLMs for decision making in interactive environments, ReAct stands out by explicitly modeling the thinking and reasoning procedure, leading to more cost-effective policy learning.

LLMs in interactive and embodied environments: LLMs have been increasingly used in interactive and embodied environments for planning and decision making. Works like SayCan and Inner Monologue leverage LLMs for robotic action planning. Inner Monologue, in particular, introduces the concept of "inner monologue" for improved decision-making. ReAct builds on such advancements by incorporating model actions and observations into a coherent stream for enhanced decision-making.

# CONCLUSION

ReAct offers a simple yet effective approach to synergize reasoning and acting in large language models. Experimental results demonstrate superior performance in various tasks with interpretable decision traces. While the method's simplicity is a strength, fine-tuning approaches may be necessary for complex tasks with large action spaces. Future work may explore the incorporation of human feedback in a complementary manner.

Reference: Research Paper published at ICLR 2023
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# ACKNOWLEDGMENTS

We thank the support and feedback of many people from Google Brain team and Princeton NLP Group. This work was supported in part by the National Science Foundation under Grant No. 2107048. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.

# REPRODUCIBILITY STATEMENT

Our main experiments are done on PaLM (Chowdhery et al., 2022), which is not an openly accessible model yet. To increase reproducibility, we have included all used prompts in Appendix C, additional experiments using GPT-3 (Brown et al., 2020) in Appendix A.1, and associated GPT-3 ReAct prompting code at ReAct-2268.

# ETHICS STATEMENT

ReAct prompts large language models to generate more human interpretable, diagnosable, and controllable task-solving trajectories than previous methods. However, hooking up a large language model with an action space to interact with external environments (e.g. the web, physical environments) has potential dangers. Our experiments minimize such risks by limiting the interactions to specific websites (Wikipedia or WebShop) that are free of private information, without any dangerous actions in the action space design.

# REFERENCES

Josh Abramson, Arun Ahuja, Iain Barr, Arthur Brussee, Federico Carnevale, Mary Cassin, Rachita Chhaparia, Stephen Clark, Bogdan Damoc, and others. "Imitating interactive intelligence," 2020. URL: Link.

Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea Finn, Chuyuan Fu, and others. "Do as i can, not as i say: Grounding language in robotic affordances," 2022. URL: Link.

Ben Alderson-Day and Charles Fernyhough. "Inner speech: development, cognitive functions, phenomenology, and neurobiology." Psychological bulletin, 141(5):931, 2015.

Alan Baddeley. "Working memory." Science, 255(5044):556–559, 1992.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, and others. "Language models are few-shot learners." Advances in neural information processing systems, 33:1877–1901, 2020.
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# References

1. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022.
2. Antonia Creswell and Murray Shanahan. Faithful reasoning using large language models, 2022. URL https://arxiv.org/abs/2208.14271.
3. Antonia Creswell, Murray Shanahan, and Irina Higgins. Selection-inference: Exploiting large language models for interpretable logical reasoning, 2022. URL https://arxiv.org/abs/2205.09712.
4. Angela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason Weston, and Michael Auli. ELI5: Long form question answering. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 3558–3567, Florence, Italy, July 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1346. URL https://aclanthology.org/P19-1346.
5. Charles Fernyhough. Vygotsky, luria, and the social brain. Self and social regulation: Social interaction and the development of social understanding and executive functions, pp. 56–79, 2010.
6. Amelia Glaese, Nat McAleese, Maja Trebacz, John Aslanides, Vlad Firoiu, Timo Ewalds, Maribeth Rauh, Laura Weidinger, Martin Chadwick, Phoebe Thacker, Lucy Campbell-Gillingham, Jonathan Uesato, Po-Sen Huang, Ramona Comanescu, Fan Yang, Abigail See, Sumanth Dathathri, Rory Greig, Charlie Chen, Doug Fritz, Jaume Sanchez Elias, Richard Green, Soˇna Mokrá, Nicholas Fernando, Boxi Wu, Rachel Foley, Susannah Young, Iason Gabriel, William Isaac, John Mellor, Demis Hassabis, Koray Kavukcuoglu, Lisa Anne Hendricks, and Geoffrey Irving. Improving alignment of dialogue agents via targeted human judgements, 2022. URL https://storage.googleapis.com/deepmind-media/DeepMind.com/Authors-Notes/sparrow/sparrow-final.pdf.
7. Ehsan Hosseini-Asl, Bryan McCann, Chien-Sheng Wu, Semih Yavuz, and Richard Socher. A simple language model for task-oriented dialogue. Advances in Neural Information Processing Systems, 33:20179–20191, 2020.
8. Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch. Language models as zero-shot, planners: Extracting actionable knowledge for embodied agents. arXiv preprint arXiv:2201.07207 2022a.
9. Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, et al. Inner monologue: Embodied reasoning through planning with language models. arXiv preprint arXiv:2207.05608, 2022b.
10. Siddharth Karamcheti, Megha Srivastava, Percy Liang, and Dorsa Sadigh. Lila: Language-informed latent actions. In CoRL, pp. 1379–1390, 2021. URL https://proceedings.mlr.press/v164/karamcheti22a.html.
11. Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners. arXiv preprint arXiv:2205.11916, 2022.
12. Angeliki Lazaridou, Elena Gribovskaya, Wojciech Stokowiec, and Nikolai Grigorev. Internet-augmented language models through few-shot prompting for open-domain question answering. arXiv preprint arXiv:2203.05115, 2022.
13. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems, 33: 9459–9474, 2020.
14. Shuang Li, Xavier Puig, Chris Paxton, Yilun Du, Clinton Wang, Linxi Fan, Tao Chen, De-An Huang, Ekin Akyürek, Anima Anandkumar, Jacob Andreas, Igor Mordatch, Antonio Torralba, and Yuke Zhu. Pre-trained language models for interactive decision-making, 2022. URL https://arxiv.org/abs/2202.01771.
---
#

# Research Paper References

# Research Paper References

Published as a conference paper at ICLR 2023

# List of References:

1. Aleksandr Romanovich Luria. Ls vygotsky and the problem of localization of functions. Neuropsychologia,
3(4):387–392, 1965.
2. Aman Madaan and Amir Yazdanbakhsh. Text and patterns: For effective chain of thought, it takes two to
tango, 2022. URL https://arxiv.org/abs/2209.07686.
3. Vincent Micheli and François Fleuret. Language models are few-shot butlers. arXiv preprint
arXiv:2104.07972, 2021.
4. Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, and John Schulman. Webgpt: Browser-assisted question-answering with human feedback, 2021. URL https://arxiv.org/abs/2112.09332.
5. Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, Charles Sutton, and Augustus Odena. Show your work: Scratchpads for intermediate computation with language models, 2021. URL https://arxiv.org/abs/2112.00114.
6. Scott Reed, Konrad Zolna, Emilio Parisotto, Sergio Gomez Colmenarejo, Alexander Novikov, Gabriel Barth-Maron, Mai Gimenez, Yury Sulsky, Jackie Kay, Jost Tobias Springenberg, Tom Eccles, Jake Bruce, Ali Razavi, Ashley Edwards, Nicolas Heess, Yutian Chen, Raia Hadsell, Oriol Vinyals, Mahyar Bordbar, and Nando de Freitas. A generalist agent, 2022. URL https://arxiv.org/abs/2205.06175.
7. Mohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan Bisk, Winson Han, Roozbeh Mottaghi, Luke Zettlemoyer, and Dieter Fox. Alfred: A benchmark for interpreting grounded instructions for everyday tasks. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 10740–10749, 2020a.
8. Mohit Shridhar, Xingdi Yuan, Marc-Alexandre Côté, Yonatan Bisk, Adam Trischler, and Matthew Hausknecht. Alfworld: Aligning text and embodied environments for interactive learning. arXiv preprint arXiv:2010.03768, 2020b.
9. Kurt Shuster, Mojtaba Komeili, Leonard Adolphs, Stephen Roller, Arthur Szlam, and Jason Weston. Language models that seek for knowledge: Modular search & generation for dialogue and prompt completion. arXiv preprint arXiv:2203.13224, 2022a.
10. Kurt Shuster, Jing Xu, Mojtaba Komeili, Da Ju, Eric Michael Smith, Stephen Roller, Megan Ung, Moya Chen, Kushal Arora, Joshua Lane, Morteza Behrooz, William Ngan, Spencer Poff, Naman Goyal, Arthur Szlam, Y-Lan Boureau, Melanie Kambadur, and Jason Weston. Blenderbot 3: a deployed conversational agent that continually learns to responsibly engage, 2022b. URL https://arxiv.org/abs/2208.03188.
11. James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal. Fever: a large-scale dataset for fact extraction and verification. arXiv preprint arXiv:1803.05355, 2018.
12. Lev S Vygotsky. Thinking and speech. The collected works of LS Vygotsky, 1:39–285, 1987.
13. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models, 2022a. URL https://arxiv.org/abs/2203.11171.
14. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. Rationale-augmented ensembles in language models. arXiv preprint arXiv:2207.00747, 2022b.
15. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903, 2022.
16. Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W Cohen, Ruslan Salakhutdinov, and Christopher D Manning. Hotpotqa: A dataset for diverse, explainable multi-hop question answering. arXiv preprint arXiv:1809.09600, 2018.
---
#

# Research Paper References

# Research Paper References

Published as a conference paper at ICLR 2023

# 1. Keep CALM and explore: Language models for action generation in text-based games

Authors: Shunyu Yao, Rohan Rao, Matthew Hausknecht, and Karthik Narasimhan

Conference: Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)

Pages: 8736–8754

Date: November 2020

Publisher: Association for Computational Linguistics

DOI: 10.18653/v1/2020.emnlp-main.704

URL: https://aclanthology.org/2020.emnlp-main.704

# 2. Webshop: Towards scalable real-world web interaction with grounded language agents

Authors: Shunyu Yao, Howard Chen, John Yang, and Karthik Narasimhan

Publication: arXiv preprint arXiv:2207.01206, 2022

# 3. Star: Bootstrapping reasoning with reasoning

Authors: Eric Zelikman, Yuhuai Wu, Jesse Mu, and Noah D. Goodman

Publication: URL https://arxiv.org/abs/2203.14465

# 4. Least-to-most prompting enables complex reasoning in large language models

Authors: Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Olivier Bousquet, Quoc Le, and Ed Chi

Publication: URL https://arxiv.org/abs/2205.10625

# 5. Adaptive information seeking for open-domain question answering

Authors: Yunchang Zhu, Liang Pang, Yanyan Lan, Huawei Shen, and Xueqi Cheng

Publication: arXiv preprint arXiv:2109.06747, 2021
---
#

# ReAct: Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

# A. ADDITIONAL RESULTS

# A.1 GPT-3 EXPERIMENTS

| |PaLM-540B|GPT-3|
|---|---|---|
|HotpotQA (exact match)|29.4|30.8|
|ALFWorld (success rate %)|70.9|78.4|

Table 5: ReAct prompting results using PaLM-540B vs. GPT-3 (text-davinci-002, greedy decoding). On HotpotQA, we randomly sample a subset of 500 validation questions. On ALFWorld, we use all 134 unseen validation task instances, and use the best prompt set according to PaLM-540B.

We run additional GPT-3 (Brown et al., 2020) experiments to confirm ReAct prompting performance is general across different large language models. As shown in Table 5, GPT-3 (text-davinci-002, greedy decoding) consistently outperforms PaLM-540B on HotpotQA and ALFWorld, possibly because it is finetuned with human instruction following. This indicates ReAct prompting is effective across different large language models on different tasks. The code for these experiments is at https://react-lm.github.io/.

# A.2 REAC T OBTAINS UP-TO-DATE KNOWLEDGE ON HOTPOTQA

Text content for section A.2...

# A.3 HUMAN-IN-THE-LOOP BEHAVIOR CORRECTION ON ALFWORLD

Text content for section A.3...

# Figure 4: Another example HotpotQA question, where the original label is outdated. Only ReAct is able to obtain the up-to-date answer thanks to real-world web interaction plus reasoning.

Text content for Figure 4...

# Figure 5: Human-in-the-loop interaction with ReAct in ALFWorld.

Text content for Figure 5...
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Experiment Details

# HOTPOTQA FINETUNING DETAILS

For all finetuning we use a batch size of 64. On PaLM-8B, we finetune ReAct and Act methods for 4,000 steps and Standard and CoT methods for 2,000 steps. On PaLM-62B, we finetune ReAct and Act methods for 4,000 steps and Standard and CoT methods for 1,000 steps. We find ReAct and Act methods generally benefit from more training steps (and more training data), while Standard and CoT methods degrade soon after finetuning.

# ALFWORLD IM-STYLE DETAILS

For the IM-style ablation, the same expert trajectories used in ReAct are reannotated with dense external feedback thoughts within these trajectories, that limit ReAct-IM to only think about (1) decomposing the current goal and (2) the current subgoal that needs to be completed. In particular, ReAct-IM lacks thoughts that (1) determine when a subgoal is completed (2) determine what the next subgoal should be (3) inducing the LLM to refer to its internal pretraining knowledge to identify where items can be within the environment.

# Figure 5: A human-in-the-loop behavior correction example with ReAct in AlfWorld.

(a) ReAct trajectory fails due to a hallucinating thought (Act 17). (b) By a human simply editing two thoughts (Act 17, 23), the ReAct trajectory produces desirable reasoning traces and actions and succeeds.
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Prompts

# HOTPOTQA

|Original Question|Answer|
|---|---|
|What is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?|1,800 to 7,000 ft|
|Musician and satirist Allie Goertz wrote a song about the "The Simpsons" character Milhouse, who Matt Groening named after who?|Richard Nixon|
|Which documentary is about Finnish rock groups, Adam Clayton Powell or The Saimaa Gesture?|The Saimaa Gesture|
|What profession does Nicholas Ray and Elia Kazan have in common?|director, screenwriter, actor|
|Which magazine was started first Arthur’s Magazine or First for Women?|Arthur’s Magazine|
|Were Pavel Urysohn and Leonid Levin known for the same type of work?|Yes|

# Act

|Question|Action|Observation|
|---|---|---|
|What is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?|Search[Colorado orogeny]|The Colorado orogeny was an episode of mountain building in Colorado and surrounding areas.|
|Musician and satirist Allie Goertz wrote a song about the "The Simpsons" character Milhouse, who Matt Groening named after who?|Search[Milhouse]|Milhouse Mussolini Van Houten is a recurring character in The Simpsons named after Richard Nixon.|
|Which documentary is about Finnish rock groups, Adam Clayton Powell or The Saimaa Gesture?|Search[Adam Clayton Powell]|Could not find Adam Clayton Powell, found a documentary about Adam Clayton Powell Jr. instead.|
|What profession does Nicholas Ray and Elia Kazan have in common?|Search[Nicholas Ray]|Nicholas Ray was a film director, screenwriter, and actor. Elia Kazan was a film and theatre director, producer, screenwriter, and actor.|
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Hotpot QA Prompts

|Action|Question|Observation|
|---|---|---|
|Action 3|Finish[director, screenwriter, actor]|Which magazine was started first Arthur’s Magazine or First for Women?|
|Action 1|Search[Arthur’s Magazine]|Arthur’s Magazine (1844-1846) was an American literary periodical published in Philadelphia in the 19th century.|
|Action 2|Search[First for Women]|First for Women is a woman’s magazine published by Bauer Media Group in the USA. The magazine was started in 1989.|
|Action 3|Finish[Arthur’s Magazine]| |

# CoT

|Question|Thought|Answer|
|---|---|---|
|What is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?|Let’s think step by step. The eastern sector of Colorado orogeny extends into the High Plains. High Plains rise in elevation from around 1,800 to 7,000 ft, so the answer is 1,800 to 7,000 ft.|1,800 to 7,000 ft|
|Musician and satirist Allie Goertz wrote a song about the "The Simpsons" character Milhouse, who Matt Groening named after who?|Let’s think step by step. Milhouse was named after U.S. president Richard Nixon, so the answer is Richard Nixon.|Richard Nixon|
|Which documentary is about Finnish rock groups, Adam Clayton Powell or The Saimaa Gesture?|Let’s think step by step. Adam Clayton Powell (film) is a documentary about an African-American politician, not Finnish rock groups. So the documentary about Finnish rock groups must instead be The Saimaa Gesture.|The Saimaa Gesture|
|What profession does Nicholas Ray and Elia Kazan have in common?|Let’s think step by step. Professions of Nicholas Ray are director, screenwriter, and actor. Professions of Elia Kazan are director, producer, screenwriter, and actor. So profession Nicholas Ray and Elia Kazan have in common is director, screenwriter, and actor.|director, screenwriter, actor|
|Which magazine was started first Arthur’s Magazine or First for Women?|Let’s think step by step. Arthur’s Magazine was started in 1844. First for Women was started in 1989. 1844 (Arthur’s Magazine) < 1989 (First for Women), so Arthur’s Magazine was started first.|Arthur’s Magazine|
|Were Pavel Urysohn and Leonid Levin known for the same type of work?|Let’s think step by step. Pavel Urysohn is a mathematician. Leonid Levin is a mathematician and computer scientist. So Pavel Urysohn and Leonid Levin have the same type of work.|Yes|

# ReAct

|Question|Thought|Action|Observation|
|---|---|---|---|
|What is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?|Thought 1: I need to search Colorado orogeny, find the area that the eastern sector of the Colorado orogeny extends into, then find the elevation range of the area.|Action 1: Search[Colorado orogeny]|The Colorado orogeny was an episode of mountain building (an orogeny) in Colorado and surrounding areas.|
| |Thought 2: It does not mention the eastern sector. So I need to look up eastern sector.|Action 2: Lookup[eastern sector]|(Result 1 / 1) The eastern sector extends into the High Plains and is called the Central Plains orogeny.|
| |Thought 3: The eastern sector of Colorado orogeny extends into the High Plains. So I need to search High Plains and find its elevation range.|Action 3: Search[High Plains]|High Plains refers to one of two distinct land regions|
| |Thought 4: I need to instead search High Plains (United States).|Action 4: Search[High Plains (United States)]| |
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Tables

Table 1: High Plains Elevation

|Observation|The High Plains are a subregion of the Great Plains. From east to west, the High Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130 m).|
|---|---|
|Thought|High Plains rise in elevation from around 1,800 to 7,000 ft, so the answer is 1,800 to 7,000 ft.|
|Action|Finish[1,800 to 7,000 ft]|

Table 2: Milhouse Naming

|Question|Musician and satirist Allie Goertz wrote a song about the "The Simpsons" character Milhouse, who Matt Groening named after who?|
|---|---|
|Thought|The question simplifies to "The Simpsons" character Milhouse is named after who. I only need to search Milhouse and find who it is named after.|
|Action|Finish[Richard Nixon]|

Table 3: Documentary Comparison

|Question|Which documentary is about Finnish rock groups, Adam Clayton Powell or The Saimaa Gesture?|
|---|---|
|Thought|I need to search Adam Clayton Powell and The Saimaa Gesture, and find which documentary is about Finnish rock groups.|
|Action|Finish[The Saimaa Gesture]|

Table 4: Common Profession

|Question|What profession does Nicholas Ray and Elia Kazan have in common?|
|---|---|
|Thought|Profession Nicholas Ray and Elia Kazan have in common is director, screenwriter, and actor.|
|Action|Finish[director, screenwriter, actor]|

Table 5: Magazine Start

|Question|Which magazine was started first Arthur’s Magazine or First for Women?|
|---|---|
|Thought|Arthur’s Magazine was started first.|
|Action|Finish[Arthur’s Magazine]|

Table 6: Work Comparison

|Question|Were Pavel Urysohn and Leonid Levin known for the same type of work?|
|---|---|
|Action|Finish[To be continued on the next page]|
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Table of Contents

- Observation 1: Pavel Samuilovich Urysohn (February 3, 1898 - August 17, 1924) was a Soviet mathematician known for his contributions in dimension theory.
- Thought 2: Pavel Urysohn is a mathematician. Search for Leonid Levin next and find his type of work.
- Action 2: Search[Leonid Levin]
- Observation 2: Leonid Anatolievich Levin is a Soviet-American mathematician and computer scientist.
- Thought 3: Leonid Levin is a mathematician and computer scientist. Pavel Urysohn and Leonid Levin have the same type of work.
- Action 3: Finish[yes]

# Additional Information

For more details on the experiments and results, please refer to the full research paper.
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# FEVER Task

# FEVER Prompts

|Claim|Answer|
|---|---|
|Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.|SUPPORTS|
|Stranger Things is set in Bloomington, Indiana.|REFUTES|
|Beautiful reached number two on the Billboard Hot 100 in 2003.|NOT ENOUGH INFO|

# Act

|Claim|Action|
|---|---|
|Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.|Search[Nikolaj Coster-Waldau]|
|Stranger Things is set in Bloomington, Indiana.|Search[Stranger Things]|
|Beautiful reached number two on the Billboard Hot 100 in 2003.|Search[Beautiful]|

# Confirmation of Thought

|Claim|Thought|Answer|
|---|---|---|
|Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.|Nikolaj William Coster-Waldau appeared in the 2009 Fox television film Virtuality, so he has worked with the Fox Broadcasting Company.|SUPPORTS|
|Stranger Things is set in Bloomington, Indiana.|Stranger Things is in the fictional town of Hawkins, Indiana, not in Bloomington, Indiana.|REFUTES|
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Experiment 1: Fever Prompts

Claim: Beautiful reached number two on the Billboard Hot 100 in 2003.

Thought: The song peaked at number two on the Billboard Hot 100 in the United States, but not sure if it was in 2003.

Answer: NOT ENOUGH INFO

ReAct: Determine if there is Observation that SUPPORTS or REFUTES a Claim, or if there is NOT ENOUGH INFORMATION.

# Experiment 2: Nikolaj Coster-Waldau

Claim: Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.

Thought 1: I need to search Nikolaj Coster-Waldau and find if he has worked with the Fox Broadcasting Company.

Action 1: Search[Nikolaj Coster-Waldau]

Observation 1: [Observation details]

Thought 2: Because he "appeared in the 2009 Fox television film Virtuality", he should have worked with the Fox Broadcasting Company.

Action 2: Finish[SUPPORTS]

# Experiment 3: Stranger Things

Claim: Stranger Things is set in Bloomington, Indiana.

Thought 1: I should search for Stranger Things, and see if it is set in Bloomington, Indiana.

Action 1: Search[Stranger Things]

Observation 1: [Observation details]

Thought 2: The observation says that it is set in a "fictional town of Hawkins, Indiana", so it is not set in Bloomington.

Action 2: Finish[REFUTES]

# Experiment 4: Beautiful Song

Claim: Beautiful reached number two on the Billboard Hot 100 in 2003.

Thought 1: I need to search the song Beautiful and find if it reached number two on the Billboard Hot 100 in 2003.

Action 1: Search[Beautiful]

Observation 1: [Observation details]

Thought 2: From suggestions, I should search "Beautiful (Christina Aguilera song)" to find the song.

Action 2: Search[Beautiful (Christina Aguilera song)]

Observation 2: [Observation details]

Thought 3: It does not mention Billboard, so I need to look up "Billboard Hot 100" to find if it reached number two on it in 2003.

Action 3: Lookup[Billboard Hot 100]

Observation 3: [Observation details]

Thought 4: It only says the song peaked at number two on the Billboard Hot 100, but not if it was in 2003. I am not sure if this claim is true or not.

Action 4: Finish[NOT ENOUGH INFO]
---
#

# ReAct: Synergizing Reasoning and Acting in Language Models

# ReAct: Synergizing Reasoning and Acting in Language Models

Published as a conference paper at ICLR 2023

# WEBSHOP

**Prompts used for the Webshop experiments in Section 4**
|Act|ReAct|
|---|---|
|Instruction: i would like a 3 ounce bottle of bright citrus deodorant for sensitive skin, and price lower than 50.00 dollars|Instruction: i would like a 3 ounce bottle of bright citrus deodorant for sensitive skin, and price lower than 50.00 dollars (add reasoning)|
|Action: search[3 ounce bright citrus deodorant sensitive skin]|Action: search[3 ounce bright citrus deodorant sensitive skin]|
|Observation: [ Back to Search ]|Observation: [ Back to Search ]|
|Page 1 (Total results: 50) [Next] [B078GWRC1J] Bright Citrus Deodorant by Earth Mama | Natural and Safe for Sensitive Skin, Pregnancy and Breastfeeding, Contains Organic Calendula 3-Ounce $10.99 [B078GTKVXY] Ginger Fresh Deodorant by Earth Mama | Natural and Safe for Sensitive Skin, Pregnancy and Breastfeeding, Contains Organic Calendula 3-Ounce $10.99 [B08KBVJ4XN] Barrel and Oak - Aluminum-Free Deodorant, Deodorant for Men, Essential Oil-Based Scent, 24-Hour Odor Protection, Cedar & Patchouli Blend, Gentle on Sensitive Skin (Mountain Sage, 2.7 oz, 2-Pack) $15.95 Action: click[B078GWRC1J] Observation: [Back to Search] scent [assorted scents][bright citrus][calming lavender][ginger [fresh] simply non-scents] size [travel set (4-pack)][3 ounce (pack of 1)][3-ounce (2 -pack)] Bright Citrus Deodorant by Earth Mama | Natural and Safe for Sensitive Skin, Pregnancy and Breastfeeding, Contains Organic Calendula 3-Ounce Price: $10.99 Rating: N.A. [Description] [Features] [Reviews] [Buy Now] Action: click[bright citrus] Observation: You have clicked bright citrus Action: click[3 ounce (pack of 1)] Observation: You have clicked 3 ounce (pack of 1) Action: click[Buy Now]|Observation: Page 1 (Total results: 50) [Next] [B078GWRC1J] Bright Citrus Deodorant by Earth Mama | Natural and Safe for Sensitive Skin, Pregnancy and Breastfeeding, Contains Organic Calendula 3-Ounce $10.99 [B078GTKVXY] $10.99 [B08KBVJ4XN] $10.99 Action: think[B078GWRC1J and B078GTKVXY are bright citrus deodorant less than 50 dollars. I can check B078GWRC1J first.] Observation: OK. Action: click[B078GWRC1J] Observation: [Back to Search] scent [assorted scents][bright citrus][calming lavender][ginger [fresh] simply non-scents] size [travel set (4-pack)][3 ounce (pack of 1)][3-ounce (2 -pack)] Bright Citrus Deodorant by Earth Mama | Natural and Safe for Sensitive Skin, Pregnancy and Breastfeeding, Contains Organic Calendula 3-Ounce Price: $10.99 Rating: N.A. [Description] [Features] [Reviews] [Buy Now] Action: click[bright citrus] Observation: You have clicked bright citrus Action: click[3 ounce (pack of 1)] Observation: You have clicked 3 ounce (pack of 1) Action: click[Buy Now]|

22
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# ALFWORLD Act Prompt Example

Table 7: An Act prompt on the ALFWorld clean task. No thoughts are provided.

You are in the middle of a room. Looking quickly around you, you see a cabinet 13, a cabinet 12, a cabinet 11, a cabinet 10, a cabinet 9, a cabinet 8, a cabinet 7, a cabinet 6, a cabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a coffeemachine 1, a countertop 1, a diningtable 1, a drawer 1, a fridge 1, a garbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin 1, a stoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster 1.

Your task is to: put a clean lettuce in diningtable.

- > go to fridge 1
- > open fridge 1
- > go to diningtable 1
- > take lettuce 1 from diningtable 1
- > go to sinkbasin 1
- > clean lettuce 1 with sinkbasin 1
- > think: Now I clean a lettuce (1). Next, I need to put it in/on diningtable 1.
- > go to diningtable 1
- > put lettuce 1 in/on diningtable 1

Page 23
---
#

# ReAct Prompt on the ALFWorld Clean Task

# Table 8: ReAct Prompt on the ALFWorld Clean Task

You are in the middle of a room. Looking quickly around you, you see:

- 13 cabinets
- 1 coffee machine
- 1 countertop
- 1 dining table
- 1 drawer
- 1 fridge
- 1 garbage can
- 1 microwave
- 3 shelves
- 1 sink basin
- 4 stove burners
- 1 toaster

Your task is to put a clean lettuce on the dining table.

Steps:

1. Find and take a lettuce.
2. Clean the lettuce with the sink basin.
3. Put the lettuce on the dining table.

Actions:

1. Check for lettuce in fridge 1.
2. Open fridge 1.
3. Take the lettuce from dining table 1.
4. Clean the lettuce with sink basin 1.
5. Put the lettuce on dining table 1.

Note: Actions and outcomes are simulated in the prompt.
---
#

# ReAct: Synergizing Reasoning and Acting in Language Models

# ReAct: Synergizing Reasoning and Acting in Language Models

Published as a conference paper at ICLR 2023

# Table 9: An ReAct-IM prompt on the ALFWorld clean task

You are in the middle of a room. Looking quickly around you, you see various items such as cabinets, a coffeemachine, a countertop, a diningtable, a drawer, a fridge, a garbagecan, a microwave, shelves, a sinkbasin, stoveburners, and a toaster. Your task is to put a clean lettuce on the diningtable.

Actions taken:

- Find a lettuce
- Open the fridge to locate the lettuce
- Take the lettuce from the diningtable
- Clean the lettuce using the sinkbasin
- Put the cleaned lettuce on the diningtable

# TRAJECTORIES

# FEVER TRAJECTORIES

We provide some trajectories produced by ReAct, CoT, and Acton on randomly selected examples from the FEVER dev set. Search results are omitted for brevity.
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Example 2491 (gt: REFUTES)

|ReAct|Claim|Thought|Action|Observation|
|---|---|---|---|---|
|ReAct|Bermuda Triangle is a loosely-defined region in the Pacific Ocean.|I need to search Bermuda Triangle and find if it is in the Pacific Ocean.|Search[Bermuda Triangle]|Reportedly haunted locations...|
|ReAct|Bermuda Triangle is a loosely-defined region in the Pacific Ocean.|The observation says that it is in the western part of the North Atlantic Ocean, so it is not in the Pacific Ocean.|Finish[REFUTES]|Episode finished|

# Example 5908 (gt: SUPPORTS)

|ReAct|Claim|Thought|Action|Observation|
|---|---|---|---|---|
|ReAct|Princess Mononoke is a film.|I need to search Princess Mononoke and find if it is a film.|Search[Princess Mononoke]|Princess Mononoke ...|
|ReAct|Princess Mononoke is a film.|From the observation, it says that Princess Mononoke is a film.|Finish[SUPPORTS]|Episode finished|

# Example 1951 (gt: REFUTES)

|ReAct|Claim|Thought|Action|Observation|
|---|---|---|---|---|
|ReAct|Soyuz was part of the American space program.|I need to search Soyuz and find if it was part of the American space program.|Search[Soyuz]|Soyuz is a transliteration...|
|ReAct|Soyuz was part of the American space program.|It does not mention the American space program, so I need to search "American space program" to find if it was part of it.|Search[American space program]|The space policy...|
|ReAct|Soyuz was part of the American space program.|It does not mention Soyuz, so I am not sure if this claim is true or not.|Finish[NOT ENOUGH INFO]|Episode finished|
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Example 3208 (gt: REFUTES)

|Claim|Reign Over Me is an American film made in 2010.|
|---|---|
|Thought 1|I need to search for Reign Over Me and find if it is an American film made in 2010.|
|Action 1|Search[Reign Over Me]|
|Observation 1|Reign Over Me ...|
|Thought 2|The observation says that it is an American film made in 2007, so it is not made in 2010.|
|Action 2|Finish[REFUTES]|
|Observation 2|Episode finished|

# ALFWORLD TRAJECTORIES

We provide an example trajectory of ReAct, Act, and ReAct-IM on the same ALFWorld game, pick_clean_then_place_in_recep-Knife-None-CounterTop-10/trial_T20190909_110445_675754.

# REACT TRAJECTORY

ReAct is able to correctly find the knife, clean it, and then place it on a countertop.
---
#

# ReAct: Synergizing Reasoning and Acting in Language Models

# ReAct: Synergizing Reasoning and Acting in Language Models

Published as a conference paper at ICLR 2023

# ReAct ALFWorld trajectory

You are in the middle of a room. Looking quickly around you, you see various items such as cabinets, a coffeemachine, countertops, drawers, fridge, garbage can, microwave, shelves, sink basin, stove burners, and a toaster.

Your task is to: put a clean knife on the countertop.

Model's Thought Process:

1. Identify the need to find and take a knife, clean it with the sink basin, and place it on the countertop.
2. Identify possible locations for a knife.
3. Start searching in cabinet 1.

|Action|Outcome|
|---|---|
|go to cabinet 1|See a bowl 1|
|go to countertop 2|Find and take knife 1|
|go to sinkbasin 1|Clean knife 1|
|go to countertop 1|Put knife 1 on the countertop|

# Act Trajectory Comparison

Act model attempts to clean the knife using the sink basin before actually going to it, leading to a breakdown in the sequence of actions. ReAct, on the other hand, would have recognized the completion of taking the knife and proceeded to the sink basin for cleaning.

Reference: Section D.2.2 of the research paper
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Act ALFWorld Trajectory

Below is a trajectory from the Act ALFWorld scenario:

[Include the trajectory text here]

# REAC T-IM Trajectory

ReAct-IM is able to correctly find the knife but is unable to clean it. The Language Model then gets stuck trying to place the knife on a countertop. One possible issue identified is the incorrect assumption that the knife is already clean, leading to confusion in the model's decision-making process. In ReAct, such subgoals are concretely captured to avoid such pitfalls.

# Tables

There are multiple tables in the research paper detailing experimental results and comparisons. For the specific content of these tables, please refer to the original document.

&copy; 2023 Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models
---
#

# ReAct-IM ALFWorld trajectory

# ReAct-IM ALFWorld trajectory

You are in the middle of a room. Looking quickly around you, you see:

- cabinet 6
- cabinet 5
- cabinet 4
- cabinet 3
- cabinet 2
- cabinet 1
- coffeemachine 1
- countertop 3
- countertop 2
- countertop 1
- drawer 3
- drawer 2
- drawer 1
- fridge 1
- garbagecan 1
- microwave 1
- shelf 3
- shelf 2
- shelf 1
- sinkbasin 1
- stoveburner 4
- stoveburner 3
- stoveburner 2
- stoveburner 1
- toaster 1

Your task is to: put a clean knife on countertop.

Interaction:

1. think: To solve the task, I need to find and take a clean knife, then put it on countertop.
2. go to countertop 1
3. take knife 1 from countertop 2
4. put knife 1 in/on countertop 1
---
#

# ReAct: Synergizing Reasoning and Acting in Language Models

# ReAct: Synergizing Reasoning and Acting in Language Models

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Table 10: Example trajectories for Webshop predicted by Act and ReAct

Compared to Act, ReAct uses reasoning to find products that satisfy all target attributes.

|Instruction|Act|ReAct|
|---|---|---|
|get me a sixteen pack of apple cinnamon freeze dried banana chips, and price lower than 50.00 dollars|Action: search[sixteen pack apple cinnamon freeze dried banana chips] Observation: [ Back to Search ] Page 1 (Total results: 50) [Next] [B0061IVFZE] ...|Action: search[sixteen pack apple cinnamon freeze dried banana chips] Observation: [ Back to Search ] Page 1 (Total results: 50) [Next] [B0061IVFZE] ...|
| |...|...|

Score: 0.125 (Act) - Score: 1.0 (ReAct)
---
#

# ReAct: Synergizing Reasoning and Acting in Language Models

# ReAct: Synergizing Reasoning and Acting in Language Models

Published as a conference paper at ICLR 2023

# More Analysis

# Success and Failure Modes Analysis

We provide some examples corresponding to the success and error mode analysis given in Sec. 3.3. Search results and non-representative steps are omitted to reduce space.

# Success: True positive

|Model|Question|Thought|Action|Observation|
|---|---|---|---|---|
|ReAct|Author David Chanoff collaboration|I need to search David Chanoff...|Search[David Chanoff]|David Chanoff is a noted author...|
|ReAct|William J. Crowe collaboration|William J. Crowe served as...|Finish[Bill Clinton]|Episode finished|

# Success: False positive

|Model|Question|Thought|Action|Observation|
|---|---|---|---|---|
|ReAct|Board game release order|I need to search San Marco...|Search[San Marco]|San Marco is one of the...|
|ReAct|University founding order|Vanderbilt University was founded...|Answer: Emory University| |

# Failure: Reasoning error

|Model|Question|Thought|Action|Observation|
|---|---|---|---|---|
|ReAct|Actress middle name|I need to search Harvey Fierstein...|Search[Harvey Fierstein]|Harvey Forbes Fierstein...|
|CoT|Comparison of ages|Danny Green was born in 1987...|Answer: Danny Green| |
---
#

# ReAct: Synergizing Reasoning and Acting in Language Models

# ReAct: Synergizing Reasoning and Acting in Language Models

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Failure: Search error

|Question|What does the goddess associated with the goddess Frigg consist of in what tales?|
|---|---|
|Thought 1|I need to search goddess Frigg and find its associated goddess.|
|Action 1|Search[goddess Frigg]|
|Observation 1|Could not find goddess Frigg. Similar: ['Frigg', 'Frigg and Freyja common origin hypothesis', 'Freyja (section Relation to Frigg and other goddesses and figures)', 'Eir (redirect from Eir (goddess))', 'Baldr'].|
|Thought 2|I need to search Frigg instead...|

# Failure: Hallucination

|Question|What was the first year a scientific journal published by an organization located in the Bronx was published?|
|---|---|
|Thought|Let’s think step by step. The first year a scientific journal published by an organization located in the Bronx was published was 1916.|
|Answer|1916 (Label: 1909)|

# Failure: Label ambiguity

|Question|What nationality is the man who developed the dictator game?|
|---|---|
|Thought 1|I need to search dictator game, find the man who developed it, then find his nationality.|
|Action 1|Search[dictator game]|
|Observation 1|The dictator game is a popular experimental instrument in social psychology and economics...|
|Action 3|Search[Amos Tversky]|
|Observation 3|Amos Nathan Tversky...|
|Thought 4|Amos Tversky is an Israeli cognitive and mathematical psychologist. So the man who developed the dictator game is Israeli.|
|Action 4|Finish[Israeli] (label: Israel-American)|

# CoT

|Question|Kurt Fuller from Stockton, CA appeared in which American Detective Comedy Drama television series created by Steve Franks?|
|---|---|
|Thought|Let’s think step by step. Kurt Fuller from Stockton, CA appeared in Psych. Psych is an American Detective Comedy Drama television series created by Steve Franks.|
|Answer|Psych (label: Psych is an American detective comedy-drama)|
#

# Research Paper: REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

# REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

Authors: Shunyu Yao*, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, Yuan Cao

Affiliations: 1Department of Computer Science, Princeton University 2Google Research, Brain team

Contact: 2{jeffreyzhao, dianyu, dunan, izhak, yuancao}@google.com 1{shunyuy, karthikn}@princeton.edu

# ABSTRACT

Large language models (LLMs) have shown impressive performance in language understanding and decision making tasks. This paper introduces ReAct, a method that combines reasoning traces and task-specific actions in LLMs to enhance their performance across various tasks. ReAct demonstrates effectiveness in question answering, fact verification, and interactive decision making tasks, outperforming existing baselines.

# 1 INTRODUCTION

The paper discusses the importance of combining verbal reasoning with task-oriented actions in human intelligence. It highlights the synergy between acting and reasoning in enabling efficient decision making and task performance. The potential of integrating verbal reasoning with interactive decision making in autonomous systems is also explored.

Key Points:

- Humans combine verbal reasoning with task-oriented actions for efficient task performance.
- Large language models show capabilities in reasoning and decision making.
- ReAct method enhances LLM performance in various tasks.

Published as a conference paper at ICLR 2023
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Table of Contents

1. Introduction
2. Comparison of Prompting Methods
3. Combining Reasoning and Acting with Language Models

# Figure 1: Comparison of Prompting Methods

(1) Comparison of 4 prompting methods, (a) Standard, (b) Chain-of-thought (CoT, Reason Only), (c) Act-only, and (d) ReAct (Reason+Act), solving a HotpotQA (Yang et al., 2018) question. (2) Comparison of (a) Act-only and (b) ReAct prompting to solve an AlfWorld (Shridhar et al., 2020b) game. In both domains, we omit in-context examples in the prompt, and only show task solving trajectories generated by the model (Act, Thought) and the environment (Obs).

# Abstract

The research paper discusses the challenges of reasoning and acting in language models, highlighting the limitations of existing methods and introducing ReAct as a novel approach to combine reasoning and acting for improved task solving.

# Conclusion

ReAct presents a promising direction for enhancing the capabilities of language models in handling complex tasks that require both reasoning and acting components. Further research and experimentation are needed to fully explore the potential benefits of this synergistic approach.

# References

- Yang et al., 2018 - HotpotQA
- Shridhar et al., 2020b - AlfWorld
- Wei et al., 2022 - Multi-modal reasoning tasks
- Ahn et al., 2022; Nakano et al., 2021; Yao et al., 2020; Huang et al., 2022a - Pre-trained language models for planning and acting
- Huang et al., 2022b - Verbal reasoning in interactive environments
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

Published as a conference paper at ICLR 2023

We conduct empirical evaluations of ReAct and state-of-the-art baselines on four diverse benchmarks: question answering (HotPotQA, Yang et al., 2018), fact verification (Fever, Thorne et al., 2018), text-based game (ALFWorld, Shridhar et al., 2020b), and webpage navigation (WebShop, Yao et al., 2022). For HotPotQA and Fever, with access to a Wikipedia API that the model can interact with, ReAct outperforms vanilla action generation models while being competitive with chain-of-thought reasoning (CoT) (Wei et al., 2022). The best approach overall is a combination of ReAct and CoT that allows for the use of both internal knowledge and externally obtained information during reasoning. On ALFWorld and WebShop, two or even one-shot ReAct prompting is able to outperform imitation or reinforcement learning methods trained with 103 ∼ 105 task instances, with an absolute improvement of 34% and 10% in success rates respectively. We also demonstrate the importance of sparse, versatile reasoning in decision making by showing consistent advantages over controlled baselines with actions only. Besides general applicability and performance boost, the combination of reasoning and acting also contributes to model interpretability, trustworthiness, and diagnosability across all domains, as humans can readily distinguish information from the model’s internal knowledge versus external environments, as well as inspect reasoning traces to understand the decision basis of model actions.

To summarize, our key contributions are the following:
1. We introduce ReAct, a novel prompt-based paradigm to synergize reasoning and acting in language models for general task solving.
2. We perform extensive experiments across diverse benchmarks to showcase the advantage of ReAct in a few-shot learning setup over prior approaches that perform either reasoning or action generation in isolation.
3. We present systematic ablations and analysis to understand the importance of acting in reasoning tasks, and reasoning in interactive tasks.
4. We analyze the limitations of ReAct under the prompting setup (i.e. limited support of reasoning and acting behaviors), and perform initial fine-tuning experiments showing the potential of ReAct to improve with additional training data. Scaling up ReAct to train and operate on more tasks and combining it with complementary paradigms like reinforcement learning could further unlock the potential of large language models.

# REAC T: SYNERGIZING REASONING + ACTING

Consider a general setup of an agent interacting with an environment for task solving. At time step t, an agent receives an observation ot ∈ O from the environment and takes an action at ∈ A following some policy π(a|ct), where ct = (o1, a1, · · · , ot−1, at−1, ot) is the context to the agent. Learning a policy is challenging when the mapping ct 7→ at is highly implicit and requires extensive computation. For example, the agent shown in Figure 1(1c) is unable to generate the correct final action (Act 4) to finish the QA task as it requires complex reasoning over the trajectory context (Question, Act 1-3, Obs 1-3). Similarly, the agent shown in Figure 1(2a) fails to comprehend from the context that sinkbasin 1 does not contain peppershaker 1, thus keep producing hallucinating actions.

The idea of ReAct is simple: we augment the agent’s action space to ˆ = A ∪ L, where L is the space of language. An action ˆt ∈ L in the language space, which we will refer to as a thought or a reasoning trace, does not affect the external environment, thus leading to no observation feedback. Instead, a thought ˆt aims to compose useful information by reasoning over the current context ct,a and update the context ct+1 = (ct, ˆt) to support future reasoning or acting. As shown in Figure 1, there could be various types of useful thoughts, e.g. decomposing task goals and create action plans (2b, Act 1; 1d, Thought 1), injecting commonsense knowledge relevant to task solving (2b, Act 1), extracting important parts from observations (1d, Thought2, 4), track progress and transit action plans (2b, Act 8), handle exceptions and adjust action plans (1d, Thought 3), and so on.

However, as the language space L is unlimited, learning in this augmented action space is difficult and requires strong language priors. In this paper, we mainly focus on the setup where a frozen large language model, PaLM-540B (Chowdhery et al., 2022), is prompted with few-shot in-context examples to generate both domain-specific actions and free-form language thoughts for task solving. Each in-context example is a human trajectory of actions, thoughts, and environment observations to solve a task instance. For the tasks where reasoning is of primary importance, we alternate the generation of thoughts and actions so that the task-solving trajectory consists of multiple thought-action-observation steps. In contrast, for decision-making tasks that potentially involve a large number of actions, thoughts only need to be generated.
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# 3 KNOWLEDGE-INTENSIVE REASONING TASKS

We begin with knowledge-intensive reasoning tasks like multi-hop question answering and fact verification. By interacting with a Wikipedia API, ReAct is able to retrieve information to support reasoning, while also using reasoning to target what to retrieve next, demonstrating a synergy of reasoning and acting.

# 3.1 SETUP

Domains: We consider two datasets challenging knowledge retrieval and reasoning: HotPotQA and FEVER. In this work, we operate in a question-only setup for both tasks, relying on internal knowledge or interacting with an external environment to support reasoning.

Action Space: We design a simple Wikipedia web API with three types of actions for interactive information retrieval: search[entity], lookup[string], and finish[answer]. This action space simulates human interaction with Wikipedia, forcing models to retrieve via explicit reasoning in language.

# 3.2 METHODS

ReAct Prompting: For HotpotQA and Fever, we randomly select cases from the training set and compose ReAct-format trajectories as few-shot exemplars in the prompts. Each trajectory consists of multiple thought-action-observation steps, using free-form thoughts for various purposes such as decomposing questions, extracting information, performing commonsense or arithmetic reasoning.

# Tables and Figures:

Figure 1(1d): Interaction with Wikipedia API

**Table 1: Datasets for Knowledge-Intensive Reasoning Tasks**
|Dataset|Description|
|---|---|
|HotPotQA|Multi-hop question answering benchmark|
|FEVER|Fact verification benchmark|

Figure 5: Human-aligned and controllable decision-making process
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Table 1: PaLM-540B prompting results on HotpotQA and Fever

|Method|HotpotQA (EM)|Fever (Acc)|
|---|---|---|
|Standard|28.7|57.1|
|CoT (Wei et al., 2022)|29.4|56.3|
|CoT-SC (Wang et al., 2022a)|33.4|60.4|
|Act|25.7|58.9|
|ReAct|27.4|60.9|
|CoT-SC → ReAct|34.2|64.6|
|ReAct → CoT-SC|35.1|62.0|
|Supervised SoTAb|67.5|89.5|

# Figure 2: PaLM-540B prompting results with respect to number of CoT-SC samples used

aHotpotQA EM is 27.1, 28.9, 33.8 for Standard, CoT, CoT-SC in Wang et al. (2022b). b(Zhu et al., 2021; Lewis et al., 2020)

# Baselines

We systematically ablate ReAct trajectories to build prompts for multiple baselines:

- (a) Standard prompting (Standard)
- (b) Chain-of-thought prompting (CoT) (Wei et al., 2022)
- (c) Acting-only prompt (Act)

# Combining Internal and External Knowledge

As detailed in Section 3.3, we observe the problem-solving process demonstrated by ReAct is more factual and grounded, whereas CoT is more accurate in formulating reasoning structure but can easily suffer from hallucinated facts or thoughts.

# Finetuning

Due to the challenge of manually annotating reasoning traces and actions at scale, a bootstraping approach similar to Zelikman et al. (2022) is considered for finetuning smaller language models (PaLM-8/62B).

# RESULTS AND OBSERVATIONS

ReAct outperforms Act consistently. Fine-tuning results also confirm the benefit of reasoning traces for more informed acting.
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Types of Success and Failure Modes

|Type|Definition|ReAct|CoT|
|---|---|---|---|
|Success|True positive|Correct reasoning trace and facts|94%|86%|
| |False positive|Hallucinated reasoning trace or facts|6%|14%|
| |Reasoning error|Wrong reasoning trace (including failing to recover from repetitive steps)|47%|16%|
|Failure|Search result error|Search return empty or does not contain useful information|23%|-|
| |Hallucination|Hallucinated reasoning trace or facts|0%|56%|
| |Label ambiguity|Right prediction but did not match the label precisely|29%|28%|

# Comparison: ReAct vs. CoT

On the other hand, ReAct outperforms CoT on Fever (60.9 vs. 56.3) and slightly lags behind CoT on HotpotQA (27.4 vs. 29.4).

# ReAct + CoT-SC Performance

ReAct + CoT-SC perform best for prompting LLMs. The best prompting method on HotpotQA and Fever are ReAct → CoT-SC and CoT-SC → ReAct respectively.

# Scaling Effect of Prompting/Finetuning

Figure 3 shows the scaling effect of prompting/finetuning. ReAct performs best for finetuning on HotpotQA. With PaLM-8/62B, prompting ReAct four methods (Standard, CoT, Act) performs worst among four methods due to the difficulty to learn both reasoning and acting from in-context examples.
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Scaling Results on HotPotQA

Figure 3 shows the scaling results for prompting and finetuning on HotPotQA with ReAct (ours) and baselines.

# Decision Making Tasks

We tested ReAct on two language-based interactive decision-making tasks: ALFWorld and WebShop.

# ALFWorld

ALFWorld is a synthetic text-based game designed for complex environments that require agents to act over long horizons with sparse rewards. It challenges agents to plan, track subgoals, and explore systematically. ReAct prompts include sparse thoughts for reasoning and acting effectively in the environment.

# WebShop

WebShop is an online shopping website environment with real-world products and human instructions. ReAct prompts involve reasoning to determine exploration strategies, purchase timing, and relevant product options based on user instructions.

# Example Prompt for WebShop:

|Action|Reasoning|
|---|---|
|Search|Determine what to explore|
|Choose product|When to buy|
|Choose options|Relevant product options|
|Buy| |

For more details and model predictions, refer to the complete research paper.
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Table 3: AlfWorld task-specific success rates (%)

|Method|Pick|Clean|Heat|Cool|Look|Pick 2|All|Method|Score|SR|
|---|---|---|---|---|---|---|---|---|---|---|
|Act (best of 6)|88|42|74|67|72|41|45|Act|62.3|30.1|
|ReAct (avg)|65|39|83|76|55|24|57|ReAct|66.6|40.0|
|ReAct (best of 6)|92|58|96|86|78|41|71|IL|59.9|29.1|
|ReAct-IM (avg)|55|59|60|55|23|24|48|IL+RL|62.4|28.7|
|ReAct-IM (best of 6)|62|68|87|57|39|33|53|Human| | |
|BUTLERg (best of 8)|33|26|70|76|17|12|22|Expert|82.1|59.6|
|BUTLER (best of 8)|46|39|74|100|22|24|37| | | |

# Results

ReAct outperforms Act on both ALFWorld and Webshop. On ALFWorld, the best ReAct trial achieves an average success rate of 71%, significantly outperforming the best Act (45%) and BUTLER (37%) trials. The advantage of ReAct over Act is consistent across six controlled trials, with relative performance gain ranging from 33% to 90% and averaging 62%. Qualitatively, Act fails to correctly decompose goals into smaller subgoals or loses track of the current state of the environment. On Webshop, ReAct achieves significantly better performance with an absolute 10% improvement over the previous best success rate.

# On the value of internal reasoning vs. external feedback

ReAct is the first demonstration of combined reasoning and action using an LLM applied to an interactive environment within a closed-loop system. Ablation experiments show that ReAct substantially outperforms IM-style prompting (ReAct-IM) with consistent advantages on five out of six tasks. ReAct's reasoning traces for decision making are flexible and sparse, allowing diverse reasoning types to be induced for different tasks.
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks, we show that ReAct leads to superior performance with interpretable decision traces.

# RELATED WORK

Language model for reasoning: The work on using Large Language Models (LLMs) for reasoning has evolved significantly. Chain-of-Thought (CoT) demonstrated the ability of LLMs to formulate their own "thinking procedure" for problem-solving. Several follow-up works have explored different aspects of reasoning, such as least-to-most prompting, zero-shot-CoT, and reasoning with self-consistency. Other approaches like Selection-Inference, STaR, and Faithful reasoning have further advanced reasoning architectures. In contrast, ReAct integrates reasoning and model actions for more accurate task handling beyond reasoning.

Language model for decision making: LLMs have shown strong capabilities in decision-making tasks beyond language generation. While models like WebGPT, BlenderBot, and Sparrow utilize LLMs for decision making in interactive environments, ReAct stands out by explicitly modeling the thinking and reasoning procedure, leading to more cost-effective policy learning.

LLMs in interactive and embodied environments: LLMs have been increasingly used in interactive and embodied environments for planning and decision making. Works like SayCan and Inner Monologue leverage LLMs for robotic action planning. Inner Monologue, in particular, introduces the concept of "inner monologue" for improved decision-making. ReAct builds on such advancements by incorporating model actions and observations into a coherent stream for enhanced decision-making.

# CONCLUSION

ReAct offers a simple yet effective approach to synergize reasoning and acting in large language models. Experimental results demonstrate superior performance in various tasks with interpretable decision traces. While the method's simplicity is a strength, fine-tuning approaches may be necessary for complex tasks with large action spaces. Future work may explore the incorporation of human feedback in a complementary manner.

Reference: Research Paper published at ICLR 2023
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# ACKNOWLEDGMENTS

We thank the support and feedback of many people from Google Brain team and Princeton NLP Group. This work was supported in part by the National Science Foundation under Grant No. 2107048. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.

# REPRODUCIBILITY STATEMENT

Our main experiments are done on PaLM (Chowdhery et al., 2022), which is not an openly accessible model yet. To increase reproducibility, we have included all used prompts in Appendix C, additional experiments using GPT-3 (Brown et al., 2020) in Appendix A.1, and associated GPT-3 ReAct prompting code at ReAct-2268.

# ETHICS STATEMENT

ReAct prompts large language models to generate more human interpretable, diagnosable, and controllable task-solving trajectories than previous methods. However, hooking up a large language model with an action space to interact with external environments (e.g. the web, physical environments) has potential dangers. Our experiments minimize such risks by limiting the interactions to specific websites (Wikipedia or WebShop) that are free of private information, without any dangerous actions in the action space design.

# REFERENCES

Josh Abramson, Arun Ahuja, Iain Barr, Arthur Brussee, Federico Carnevale, Mary Cassin, Rachita Chhaparia, Stephen Clark, Bogdan Damoc, and others. "Imitating interactive intelligence," 2020. URL: Link.

Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea Finn, Chuyuan Fu, and others. "Do as i can, not as i say: Grounding language in robotic affordances," 2022. URL: Link.

Ben Alderson-Day and Charles Fernyhough. "Inner speech: development, cognitive functions, phenomenology, and neurobiology." Psychological bulletin, 141(5):931, 2015.

Alan Baddeley. "Working memory." Science, 255(5044):556–559, 1992.

Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, and others. "Language models are few-shot learners." Advances in neural information processing systems, 33:1877–1901, 2020.
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# References

1. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022.
2. Antonia Creswell and Murray Shanahan. Faithful reasoning using large language models, 2022. URL https://arxiv.org/abs/2208.14271.
3. Antonia Creswell, Murray Shanahan, and Irina Higgins. Selection-inference: Exploiting large language models for interpretable logical reasoning, 2022. URL https://arxiv.org/abs/2205.09712.
4. Angela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason Weston, and Michael Auli. ELI5: Long form question answering. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pp. 3558–3567, Florence, Italy, July 2019. Association for Computational Linguistics. doi: 10.18653/v1/P19-1346. URL https://aclanthology.org/P19-1346.
5. Charles Fernyhough. Vygotsky, luria, and the social brain. Self and social regulation: Social interaction and the development of social understanding and executive functions, pp. 56–79, 2010.
6. Amelia Glaese, Nat McAleese, Maja Trebacz, John Aslanides, Vlad Firoiu, Timo Ewalds, Maribeth Rauh, Laura Weidinger, Martin Chadwick, Phoebe Thacker, Lucy Campbell-Gillingham, Jonathan Uesato, Po-Sen Huang, Ramona Comanescu, Fan Yang, Abigail See, Sumanth Dathathri, Rory Greig, Charlie Chen, Doug Fritz, Jaume Sanchez Elias, Richard Green, Soˇna Mokrá, Nicholas Fernando, Boxi Wu, Rachel Foley, Susannah Young, Iason Gabriel, William Isaac, John Mellor, Demis Hassabis, Koray Kavukcuoglu, Lisa Anne Hendricks, and Geoffrey Irving. Improving alignment of dialogue agents via targeted human judgements, 2022. URL https://storage.googleapis.com/deepmind-media/DeepMind.com/Authors-Notes/sparrow/sparrow-final.pdf.
7. Ehsan Hosseini-Asl, Bryan McCann, Chien-Sheng Wu, Semih Yavuz, and Richard Socher. A simple language model for task-oriented dialogue. Advances in Neural Information Processing Systems, 33:20179–20191, 2020.
8. Wenlong Huang, Pieter Abbeel, Deepak Pathak, and Igor Mordatch. Language models as zero-shot, planners: Extracting actionable knowledge for embodied agents. arXiv preprint arXiv:2201.07207 2022a.
9. Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, et al. Inner monologue: Embodied reasoning through planning with language models. arXiv preprint arXiv:2207.05608, 2022b.
10. Siddharth Karamcheti, Megha Srivastava, Percy Liang, and Dorsa Sadigh. Lila: Language-informed latent actions. In CoRL, pp. 1379–1390, 2021. URL https://proceedings.mlr.press/v164/karamcheti22a.html.
11. Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners. arXiv preprint arXiv:2205.11916, 2022.
12. Angeliki Lazaridou, Elena Gribovskaya, Wojciech Stokowiec, and Nikolai Grigorev. Internet-augmented language models through few-shot prompting for open-domain question answering. arXiv preprint arXiv:2203.05115, 2022.
13. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems, 33: 9459–9474, 2020.
14. Shuang Li, Xavier Puig, Chris Paxton, Yilun Du, Clinton Wang, Linxi Fan, Tao Chen, De-An Huang, Ekin Akyürek, Anima Anandkumar, Jacob Andreas, Igor Mordatch, Antonio Torralba, and Yuke Zhu. Pre-trained language models for interactive decision-making, 2022. URL https://arxiv.org/abs/2202.01771.
---
#

# Research Paper References

# Research Paper References

Published as a conference paper at ICLR 2023

# List of References:

1. Aleksandr Romanovich Luria. Ls vygotsky and the problem of localization of functions. Neuropsychologia,
3(4):387–392, 1965.
2. Aman Madaan and Amir Yazdanbakhsh. Text and patterns: For effective chain of thought, it takes two to
tango, 2022. URL https://arxiv.org/abs/2209.07686.
3. Vincent Micheli and François Fleuret. Language models are few-shot butlers. arXiv preprint
arXiv:2104.07972, 2021.
4. Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, and John Schulman. Webgpt: Browser-assisted question-answering with human feedback, 2021. URL https://arxiv.org/abs/2112.09332.
5. Maxwell Nye, Anders Johan Andreassen, Guy Gur-Ari, Henryk Michalewski, Jacob Austin, David Bieber, David Dohan, Aitor Lewkowycz, Maarten Bosma, David Luan, Charles Sutton, and Augustus Odena. Show your work: Scratchpads for intermediate computation with language models, 2021. URL https://arxiv.org/abs/2112.00114.
6. Scott Reed, Konrad Zolna, Emilio Parisotto, Sergio Gomez Colmenarejo, Alexander Novikov, Gabriel Barth-Maron, Mai Gimenez, Yury Sulsky, Jackie Kay, Jost Tobias Springenberg, Tom Eccles, Jake Bruce, Ali Razavi, Ashley Edwards, Nicolas Heess, Yutian Chen, Raia Hadsell, Oriol Vinyals, Mahyar Bordbar, and Nando de Freitas. A generalist agent, 2022. URL https://arxiv.org/abs/2205.06175.
7. Mohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan Bisk, Winson Han, Roozbeh Mottaghi, Luke Zettlemoyer, and Dieter Fox. Alfred: A benchmark for interpreting grounded instructions for everyday tasks. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pp. 10740–10749, 2020a.
8. Mohit Shridhar, Xingdi Yuan, Marc-Alexandre Côté, Yonatan Bisk, Adam Trischler, and Matthew Hausknecht. Alfworld: Aligning text and embodied environments for interactive learning. arXiv preprint arXiv:2010.03768, 2020b.
9. Kurt Shuster, Mojtaba Komeili, Leonard Adolphs, Stephen Roller, Arthur Szlam, and Jason Weston. Language models that seek for knowledge: Modular search & generation for dialogue and prompt completion. arXiv preprint arXiv:2203.13224, 2022a.
10. Kurt Shuster, Jing Xu, Mojtaba Komeili, Da Ju, Eric Michael Smith, Stephen Roller, Megan Ung, Moya Chen, Kushal Arora, Joshua Lane, Morteza Behrooz, William Ngan, Spencer Poff, Naman Goyal, Arthur Szlam, Y-Lan Boureau, Melanie Kambadur, and Jason Weston. Blenderbot 3: a deployed conversational agent that continually learns to responsibly engage, 2022b. URL https://arxiv.org/abs/2208.03188.
11. James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal. Fever: a large-scale dataset for fact extraction and verification. arXiv preprint arXiv:1803.05355, 2018.
12. Lev S Vygotsky. Thinking and speech. The collected works of LS Vygotsky, 1:39–285, 1987.
13. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models, 2022a. URL https://arxiv.org/abs/2203.11171.
14. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. Rationale-augmented ensembles in language models. arXiv preprint arXiv:2207.00747, 2022b.
15. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large language models. arXiv preprint arXiv:2201.11903, 2022.
16. Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W Cohen, Ruslan Salakhutdinov, and Christopher D Manning. Hotpotqa: A dataset for diverse, explainable multi-hop question answering. arXiv preprint arXiv:1809.09600, 2018.
---
#

# Research Paper References

# Research Paper References

Published as a conference paper at ICLR 2023

# 1. Keep CALM and explore: Language models for action generation in text-based games

Authors: Shunyu Yao, Rohan Rao, Matthew Hausknecht, and Karthik Narasimhan

Conference: Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)

Pages: 8736–8754

Date: November 2020

Publisher: Association for Computational Linguistics

DOI: 10.18653/v1/2020.emnlp-main.704

URL: https://aclanthology.org/2020.emnlp-main.704

# 2. Webshop: Towards scalable real-world web interaction with grounded language agents

Authors: Shunyu Yao, Howard Chen, John Yang, and Karthik Narasimhan

Publication: arXiv preprint arXiv:2207.01206, 2022

# 3. Star: Bootstrapping reasoning with reasoning

Authors: Eric Zelikman, Yuhuai Wu, Jesse Mu, and Noah D. Goodman

Publication: URL https://arxiv.org/abs/2203.14465

# 4. Least-to-most prompting enables complex reasoning in large language models

Authors: Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Olivier Bousquet, Quoc Le, and Ed Chi

Publication: URL https://arxiv.org/abs/2205.10625

# 5. Adaptive information seeking for open-domain question answering

Authors: Yunchang Zhu, Liang Pang, Yanyan Lan, Huawei Shen, and Xueqi Cheng

Publication: arXiv preprint arXiv:2109.06747, 2021
---
#

# ReAct: Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

# A. ADDITIONAL RESULTS

# A.1 GPT-3 EXPERIMENTS

| |PaLM-540B|GPT-3|
|---|---|---|
|HotpotQA (exact match)|29.4|30.8|
|ALFWorld (success rate %)|70.9|78.4|

Table 5: ReAct prompting results using PaLM-540B vs. GPT-3 (text-davinci-002, greedy decoding). On HotpotQA, we randomly sample a subset of 500 validation questions. On ALFWorld, we use all 134 unseen validation task instances, and use the best prompt set according to PaLM-540B.

We run additional GPT-3 (Brown et al., 2020) experiments to confirm ReAct prompting performance is general across different large language models. As shown in Table 5, GPT-3 (text-davinci-002, greedy decoding) consistently outperforms PaLM-540B on HotpotQA and ALFWorld, possibly because it is finetuned with human instruction following. This indicates ReAct prompting is effective across different large language models on different tasks. The code for these experiments is at https://react-lm.github.io/.

# A.2 REAC T OBTAINS UP-TO-DATE KNOWLEDGE ON HOTPOTQA

Text content for section A.2...

# A.3 HUMAN-IN-THE-LOOP BEHAVIOR CORRECTION ON ALFWORLD

Text content for section A.3...

# Figure 4: Another example HotpotQA question, where the original label is outdated. Only ReAct is able to obtain the up-to-date answer thanks to real-world web interaction plus reasoning.

Text content for Figure 4...

# Figure 5: Human-in-the-loop interaction with ReAct in ALFWorld.

Text content for Figure 5...
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Experiment Details

# HOTPOTQA FINETUNING DETAILS

For all finetuning we use a batch size of 64. On PaLM-8B, we finetune ReAct and Act methods for 4,000 steps and Standard and CoT methods for 2,000 steps. On PaLM-62B, we finetune ReAct and Act methods for 4,000 steps and Standard and CoT methods for 1,000 steps. We find ReAct and Act methods generally benefit from more training steps (and more training data), while Standard and CoT methods degrade soon after finetuning.

# ALFWORLD IM-STYLE DETAILS

For the IM-style ablation, the same expert trajectories used in ReAct are reannotated with dense external feedback thoughts within these trajectories, that limit ReAct-IM to only think about (1) decomposing the current goal and (2) the current subgoal that needs to be completed. In particular, ReAct-IM lacks thoughts that (1) determine when a subgoal is completed (2) determine what the next subgoal should be (3) inducing the LLM to refer to its internal pretraining knowledge to identify where items can be within the environment.

# Figure 5: A human-in-the-loop behavior correction example with ReAct in AlfWorld.

(a) ReAct trajectory fails due to a hallucinating thought (Act 17). (b) By a human simply editing two thoughts (Act 17, 23), the ReAct trajectory produces desirable reasoning traces and actions and succeeds.
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Prompts

# HOTPOTQA

|Original Question|Answer|
|---|---|
|What is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?|1,800 to 7,000 ft|
|Musician and satirist Allie Goertz wrote a song about the "The Simpsons" character Milhouse, who Matt Groening named after who?|Richard Nixon|
|Which documentary is about Finnish rock groups, Adam Clayton Powell or The Saimaa Gesture?|The Saimaa Gesture|
|What profession does Nicholas Ray and Elia Kazan have in common?|director, screenwriter, actor|
|Which magazine was started first Arthur’s Magazine or First for Women?|Arthur’s Magazine|
|Were Pavel Urysohn and Leonid Levin known for the same type of work?|Yes|

# Act

|Question|Action|Observation|
|---|---|---|
|What is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?|Search[Colorado orogeny]|The Colorado orogeny was an episode of mountain building in Colorado and surrounding areas.|
|Musician and satirist Allie Goertz wrote a song about the "The Simpsons" character Milhouse, who Matt Groening named after who?|Search[Milhouse]|Milhouse Mussolini Van Houten is a recurring character in The Simpsons named after Richard Nixon.|
|Which documentary is about Finnish rock groups, Adam Clayton Powell or The Saimaa Gesture?|Search[Adam Clayton Powell]|Could not find Adam Clayton Powell, found a documentary about Adam Clayton Powell Jr. instead.|
|What profession does Nicholas Ray and Elia Kazan have in common?|Search[Nicholas Ray]|Nicholas Ray was a film director, screenwriter, and actor. Elia Kazan was a film and theatre director, producer, screenwriter, and actor.|
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Hotpot QA Prompts

|Action|Question|Observation|
|---|---|---|
|Action 3|Finish[director, screenwriter, actor]|Which magazine was started first Arthur’s Magazine or First for Women?|
|Action 1|Search[Arthur’s Magazine]|Arthur’s Magazine (1844-1846) was an American literary periodical published in Philadelphia in the 19th century.|
|Action 2|Search[First for Women]|First for Women is a woman’s magazine published by Bauer Media Group in the USA. The magazine was started in 1989.|
|Action 3|Finish[Arthur’s Magazine]| |

# CoT

|Question|Thought|Answer|
|---|---|---|
|What is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?|Let’s think step by step. The eastern sector of Colorado orogeny extends into the High Plains. High Plains rise in elevation from around 1,800 to 7,000 ft, so the answer is 1,800 to 7,000 ft.|1,800 to 7,000 ft|
|Musician and satirist Allie Goertz wrote a song about the "The Simpsons" character Milhouse, who Matt Groening named after who?|Let’s think step by step. Milhouse was named after U.S. president Richard Nixon, so the answer is Richard Nixon.|Richard Nixon|
|Which documentary is about Finnish rock groups, Adam Clayton Powell or The Saimaa Gesture?|Let’s think step by step. Adam Clayton Powell (film) is a documentary about an African-American politician, not Finnish rock groups. So the documentary about Finnish rock groups must instead be The Saimaa Gesture.|The Saimaa Gesture|
|What profession does Nicholas Ray and Elia Kazan have in common?|Let’s think step by step. Professions of Nicholas Ray are director, screenwriter, and actor. Professions of Elia Kazan are director, producer, screenwriter, and actor. So profession Nicholas Ray and Elia Kazan have in common is director, screenwriter, and actor.|director, screenwriter, actor|
|Which magazine was started first Arthur’s Magazine or First for Women?|Let’s think step by step. Arthur’s Magazine was started in 1844. First for Women was started in 1989. 1844 (Arthur’s Magazine) < 1989 (First for Women), so Arthur’s Magazine was started first.|Arthur’s Magazine|
|Were Pavel Urysohn and Leonid Levin known for the same type of work?|Let’s think step by step. Pavel Urysohn is a mathematician. Leonid Levin is a mathematician and computer scientist. So Pavel Urysohn and Leonid Levin have the same type of work.|Yes|

# ReAct

|Question|Thought|Action|Observation|
|---|---|---|---|
|What is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?|Thought 1: I need to search Colorado orogeny, find the area that the eastern sector of the Colorado orogeny extends into, then find the elevation range of the area.|Action 1: Search[Colorado orogeny]|The Colorado orogeny was an episode of mountain building (an orogeny) in Colorado and surrounding areas.|
| |Thought 2: It does not mention the eastern sector. So I need to look up eastern sector.|Action 2: Lookup[eastern sector]|(Result 1 / 1) The eastern sector extends into the High Plains and is called the Central Plains orogeny.|
| |Thought 3: The eastern sector of Colorado orogeny extends into the High Plains. So I need to search High Plains and find its elevation range.|Action 3: Search[High Plains]|High Plains refers to one of two distinct land regions|
| |Thought 4: I need to instead search High Plains (United States).|Action 4: Search[High Plains (United States)]| |
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Tables

Table 1: High Plains Elevation

|Observation|The High Plains are a subregion of the Great Plains. From east to west, the High Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130 m).|
|---|---|
|Thought|High Plains rise in elevation from around 1,800 to 7,000 ft, so the answer is 1,800 to 7,000 ft.|
|Action|Finish[1,800 to 7,000 ft]|

Table 2: Milhouse Naming

|Question|Musician and satirist Allie Goertz wrote a song about the "The Simpsons" character Milhouse, who Matt Groening named after who?|
|---|---|
|Thought|The question simplifies to "The Simpsons" character Milhouse is named after who. I only need to search Milhouse and find who it is named after.|
|Action|Finish[Richard Nixon]|

Table 3: Documentary Comparison

|Question|Which documentary is about Finnish rock groups, Adam Clayton Powell or The Saimaa Gesture?|
|---|---|
|Thought|I need to search Adam Clayton Powell and The Saimaa Gesture, and find which documentary is about Finnish rock groups.|
|Action|Finish[The Saimaa Gesture]|

Table 4: Common Profession

|Question|What profession does Nicholas Ray and Elia Kazan have in common?|
|---|---|
|Thought|Profession Nicholas Ray and Elia Kazan have in common is director, screenwriter, and actor.|
|Action|Finish[director, screenwriter, actor]|

Table 5: Magazine Start

|Question|Which magazine was started first Arthur’s Magazine or First for Women?|
|---|---|
|Thought|Arthur’s Magazine was started first.|
|Action|Finish[Arthur’s Magazine]|

Table 6: Work Comparison

|Question|Were Pavel Urysohn and Leonid Levin known for the same type of work?|
|---|---|
|Action|Finish[To be continued on the next page]|
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Table of Contents

- Observation 1: Pavel Samuilovich Urysohn (February 3, 1898 - August 17, 1924) was a Soviet mathematician known for his contributions in dimension theory.
- Thought 2: Pavel Urysohn is a mathematician. Search for Leonid Levin next and find his type of work.
- Action 2: Search[Leonid Levin]
- Observation 2: Leonid Anatolievich Levin is a Soviet-American mathematician and computer scientist.
- Thought 3: Leonid Levin is a mathematician and computer scientist. Pavel Urysohn and Leonid Levin have the same type of work.
- Action 3: Finish[yes]

# Additional Information

For more details on the experiments and results, please refer to the full research paper.
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# FEVER Task

# FEVER Prompts

|Claim|Answer|
|---|---|
|Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.|SUPPORTS|
|Stranger Things is set in Bloomington, Indiana.|REFUTES|
|Beautiful reached number two on the Billboard Hot 100 in 2003.|NOT ENOUGH INFO|

# Act

|Claim|Action|
|---|---|
|Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.|Search[Nikolaj Coster-Waldau]|
|Stranger Things is set in Bloomington, Indiana.|Search[Stranger Things]|
|Beautiful reached number two on the Billboard Hot 100 in 2003.|Search[Beautiful]|

# Confirmation of Thought

|Claim|Thought|Answer|
|---|---|---|
|Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.|Nikolaj William Coster-Waldau appeared in the 2009 Fox television film Virtuality, so he has worked with the Fox Broadcasting Company.|SUPPORTS|
|Stranger Things is set in Bloomington, Indiana.|Stranger Things is in the fictional town of Hawkins, Indiana, not in Bloomington, Indiana.|REFUTES|
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Experiment 1: Fever Prompts

Claim: Beautiful reached number two on the Billboard Hot 100 in 2003.

Thought: The song peaked at number two on the Billboard Hot 100 in the United States, but not sure if it was in 2003.

Answer: NOT ENOUGH INFO

ReAct: Determine if there is Observation that SUPPORTS or REFUTES a Claim, or if there is NOT ENOUGH INFORMATION.

# Experiment 2: Nikolaj Coster-Waldau

Claim: Nikolaj Coster-Waldau worked with the Fox Broadcasting Company.

Thought 1: I need to search Nikolaj Coster-Waldau and find if he has worked with the Fox Broadcasting Company.

Action 1: Search[Nikolaj Coster-Waldau]

Observation 1: [Observation details]

Thought 2: Because he "appeared in the 2009 Fox television film Virtuality", he should have worked with the Fox Broadcasting Company.

Action 2: Finish[SUPPORTS]

# Experiment 3: Stranger Things

Claim: Stranger Things is set in Bloomington, Indiana.

Thought 1: I should search for Stranger Things, and see if it is set in Bloomington, Indiana.

Action 1: Search[Stranger Things]

Observation 1: [Observation details]

Thought 2: The observation says that it is set in a "fictional town of Hawkins, Indiana", so it is not set in Bloomington.

Action 2: Finish[REFUTES]

# Experiment 4: Beautiful Song

Claim: Beautiful reached number two on the Billboard Hot 100 in 2003.

Thought 1: I need to search the song Beautiful and find if it reached number two on the Billboard Hot 100 in 2003.

Action 1: Search[Beautiful]

Observation 1: [Observation details]

Thought 2: From suggestions, I should search "Beautiful (Christina Aguilera song)" to find the song.

Action 2: Search[Beautiful (Christina Aguilera song)]

Observation 2: [Observation details]

Thought 3: It does not mention Billboard, so I need to look up "Billboard Hot 100" to find if it reached number two on it in 2003.

Action 3: Lookup[Billboard Hot 100]

Observation 3: [Observation details]

Thought 4: It only says the song peaked at number two on the Billboard Hot 100, but not if it was in 2003. I am not sure if this claim is true or not.

Action 4: Finish[NOT ENOUGH INFO]
---
#

# ReAct: Synergizing Reasoning and Acting in Language Models

# ReAct: Synergizing Reasoning and Acting in Language Models

Published as a conference paper at ICLR 2023

# WEBSHOP

**Prompts used for the Webshop experiments in Section 4**
|Act|ReAct|
|---|---|
|Instruction: i would like a 3 ounce bottle of bright citrus deodorant for sensitive skin, and price lower than 50.00 dollars|Instruction: i would like a 3 ounce bottle of bright citrus deodorant for sensitive skin, and price lower than 50.00 dollars (add reasoning)|
|Action: search[3 ounce bright citrus deodorant sensitive skin]|Action: search[3 ounce bright citrus deodorant sensitive skin]|
|Observation: [ Back to Search ]|Observation: [ Back to Search ]|
|Page 1 (Total results: 50) [Next] [B078GWRC1J] Bright Citrus Deodorant by Earth Mama | Natural and Safe for Sensitive Skin, Pregnancy and Breastfeeding, Contains Organic Calendula 3-Ounce $10.99 [B078GTKVXY] Ginger Fresh Deodorant by Earth Mama | Natural and Safe for Sensitive Skin, Pregnancy and Breastfeeding, Contains Organic Calendula 3-Ounce $10.99 [B08KBVJ4XN] Barrel and Oak - Aluminum-Free Deodorant, Deodorant for Men, Essential Oil-Based Scent, 24-Hour Odor Protection, Cedar & Patchouli Blend, Gentle on Sensitive Skin (Mountain Sage, 2.7 oz, 2-Pack) $15.95 Action: click[B078GWRC1J] Observation: [Back to Search] scent [assorted scents][bright citrus][calming lavender][ginger [fresh] simply non-scents] size [travel set (4-pack)][3 ounce (pack of 1)][3-ounce (2 -pack)] Bright Citrus Deodorant by Earth Mama | Natural and Safe for Sensitive Skin, Pregnancy and Breastfeeding, Contains Organic Calendula 3-Ounce Price: $10.99 Rating: N.A. [Description] [Features] [Reviews] [Buy Now] Action: click[bright citrus] Observation: You have clicked bright citrus Action: click[3 ounce (pack of 1)] Observation: You have clicked 3 ounce (pack of 1) Action: click[Buy Now]|Observation: Page 1 (Total results: 50) [Next] [B078GWRC1J] Bright Citrus Deodorant by Earth Mama | Natural and Safe for Sensitive Skin, Pregnancy and Breastfeeding, Contains Organic Calendula 3-Ounce $10.99 [B078GTKVXY] $10.99 [B08KBVJ4XN] $10.99 Action: think[B078GWRC1J and B078GTKVXY are bright citrus deodorant less than 50 dollars. I can check B078GWRC1J first.] Observation: OK. Action: click[B078GWRC1J] Observation: [Back to Search] scent [assorted scents][bright citrus][calming lavender][ginger [fresh] simply non-scents] size [travel set (4-pack)][3 ounce (pack of 1)][3-ounce (2 -pack)] Bright Citrus Deodorant by Earth Mama | Natural and Safe for Sensitive Skin, Pregnancy and Breastfeeding, Contains Organic Calendula 3-Ounce Price: $10.99 Rating: N.A. [Description] [Features] [Reviews] [Buy Now] Action: click[bright citrus] Observation: You have clicked bright citrus Action: click[3 ounce (pack of 1)] Observation: You have clicked 3 ounce (pack of 1) Action: click[Buy Now]|

22
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# ALFWORLD Act Prompt Example

Table 7: An Act prompt on the ALFWorld clean task. No thoughts are provided.

You are in the middle of a room. Looking quickly around you, you see a cabinet 13, a cabinet 12, a cabinet 11, a cabinet 10, a cabinet 9, a cabinet 8, a cabinet 7, a cabinet 6, a cabinet 5, a cabinet 4, a cabinet 3, a cabinet 2, a cabinet 1, a coffeemachine 1, a countertop 1, a diningtable 1, a drawer 1, a fridge 1, a garbagecan 1, a microwave 1, a shelf 3, a shelf 2, a shelf 1, a sinkbasin 1, a stoveburner 4, a stoveburner 3, a stoveburner 2, a stoveburner 1, and a toaster 1.

Your task is to: put a clean lettuce in diningtable.

- > go to fridge 1
- > open fridge 1
- > go to diningtable 1
- > take lettuce 1 from diningtable 1
- > go to sinkbasin 1
- > clean lettuce 1 with sinkbasin 1
- > think: Now I clean a lettuce (1). Next, I need to put it in/on diningtable 1.
- > go to diningtable 1
- > put lettuce 1 in/on diningtable 1

Page 23
---
#

# ReAct Prompt on the ALFWorld Clean Task

# Table 8: ReAct Prompt on the ALFWorld Clean Task

You are in the middle of a room. Looking quickly around you, you see:

- 13 cabinets
- 1 coffee machine
- 1 countertop
- 1 dining table
- 1 drawer
- 1 fridge
- 1 garbage can
- 1 microwave
- 3 shelves
- 1 sink basin
- 4 stove burners
- 1 toaster

Your task is to put a clean lettuce on the dining table.

Steps:

1. Find and take a lettuce.
2. Clean the lettuce with the sink basin.
3. Put the lettuce on the dining table.

Actions:

1. Check for lettuce in fridge 1.
2. Open fridge 1.
3. Take the lettuce from dining table 1.
4. Clean the lettuce with sink basin 1.
5. Put the lettuce on dining table 1.

Note: Actions and outcomes are simulated in the prompt.
---
#

# ReAct: Synergizing Reasoning and Acting in Language Models

# ReAct: Synergizing Reasoning and Acting in Language Models

Published as a conference paper at ICLR 2023

# Table 9: An ReAct-IM prompt on the ALFWorld clean task

You are in the middle of a room. Looking quickly around you, you see various items such as cabinets, a coffeemachine, a countertop, a diningtable, a drawer, a fridge, a garbagecan, a microwave, shelves, a sinkbasin, stoveburners, and a toaster. Your task is to put a clean lettuce on the diningtable.

Actions taken:

- Find a lettuce
- Open the fridge to locate the lettuce
- Take the lettuce from the diningtable
- Clean the lettuce using the sinkbasin
- Put the cleaned lettuce on the diningtable

# TRAJECTORIES

# FEVER TRAJECTORIES

We provide some trajectories produced by ReAct, CoT, and Acton on randomly selected examples from the FEVER dev set. Search results are omitted for brevity.
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Example 2491 (gt: REFUTES)

|ReAct|Claim|Thought|Action|Observation|
|---|---|---|---|---|
|ReAct|Bermuda Triangle is a loosely-defined region in the Pacific Ocean.|I need to search Bermuda Triangle and find if it is in the Pacific Ocean.|Search[Bermuda Triangle]|Reportedly haunted locations...|
|ReAct|Bermuda Triangle is a loosely-defined region in the Pacific Ocean.|The observation says that it is in the western part of the North Atlantic Ocean, so it is not in the Pacific Ocean.|Finish[REFUTES]|Episode finished|

# Example 5908 (gt: SUPPORTS)

|ReAct|Claim|Thought|Action|Observation|
|---|---|---|---|---|
|ReAct|Princess Mononoke is a film.|I need to search Princess Mononoke and find if it is a film.|Search[Princess Mononoke]|Princess Mononoke ...|
|ReAct|Princess Mononoke is a film.|From the observation, it says that Princess Mononoke is a film.|Finish[SUPPORTS]|Episode finished|

# Example 1951 (gt: REFUTES)

|ReAct|Claim|Thought|Action|Observation|
|---|---|---|---|---|
|ReAct|Soyuz was part of the American space program.|I need to search Soyuz and find if it was part of the American space program.|Search[Soyuz]|Soyuz is a transliteration...|
|ReAct|Soyuz was part of the American space program.|It does not mention the American space program, so I need to search "American space program" to find if it was part of it.|Search[American space program]|The space policy...|
|ReAct|Soyuz was part of the American space program.|It does not mention Soyuz, so I am not sure if this claim is true or not.|Finish[NOT ENOUGH INFO]|Episode finished|
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Example 3208 (gt: REFUTES)

|Claim|Reign Over Me is an American film made in 2010.|
|---|---|
|Thought 1|I need to search for Reign Over Me and find if it is an American film made in 2010.|
|Action 1|Search[Reign Over Me]|
|Observation 1|Reign Over Me ...|
|Thought 2|The observation says that it is an American film made in 2007, so it is not made in 2010.|
|Action 2|Finish[REFUTES]|
|Observation 2|Episode finished|

# ALFWORLD TRAJECTORIES

We provide an example trajectory of ReAct, Act, and ReAct-IM on the same ALFWorld game, pick_clean_then_place_in_recep-Knife-None-CounterTop-10/trial_T20190909_110445_675754.

# REACT TRAJECTORY

ReAct is able to correctly find the knife, clean it, and then place it on a countertop.
---
#

# ReAct: Synergizing Reasoning and Acting in Language Models

# ReAct: Synergizing Reasoning and Acting in Language Models

Published as a conference paper at ICLR 2023

# ReAct ALFWorld trajectory

You are in the middle of a room. Looking quickly around you, you see various items such as cabinets, a coffeemachine, countertops, drawers, fridge, garbage can, microwave, shelves, sink basin, stove burners, and a toaster.

Your task is to: put a clean knife on the countertop.

Model's Thought Process:

1. Identify the need to find and take a knife, clean it with the sink basin, and place it on the countertop.
2. Identify possible locations for a knife.
3. Start searching in cabinet 1.

|Action|Outcome|
|---|---|
|go to cabinet 1|See a bowl 1|
|go to countertop 2|Find and take knife 1|
|go to sinkbasin 1|Clean knife 1|
|go to countertop 1|Put knife 1 on the countertop|

# Act Trajectory Comparison

Act model attempts to clean the knife using the sink basin before actually going to it, leading to a breakdown in the sequence of actions. ReAct, on the other hand, would have recognized the completion of taking the knife and proceeded to the sink basin for cleaning.

Reference: Section D.2.2 of the research paper
---
#

# Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models

# REAC T: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Act ALFWorld Trajectory

Below is a trajectory from the Act ALFWorld scenario:

[Include the trajectory text here]

# REAC T-IM Trajectory

ReAct-IM is able to correctly find the knife but is unable to clean it. The Language Model then gets stuck trying to place the knife on a countertop. One possible issue identified is the incorrect assumption that the knife is already clean, leading to confusion in the model's decision-making process. In ReAct, such subgoals are concretely captured to avoid such pitfalls.

# Tables

There are multiple tables in the research paper detailing experimental results and comparisons. For the specific content of these tables, please refer to the original document.

&copy; 2023 Research Paper: ReAct - Synergizing Reasoning and Acting in Language Models
---
#

# ReAct-IM ALFWorld trajectory

# ReAct-IM ALFWorld trajectory

You are in the middle of a room. Looking quickly around you, you see:

- cabinet 6
- cabinet 5
- cabinet 4
- cabinet 3
- cabinet 2
- cabinet 1
- coffeemachine 1
- countertop 3
- countertop 2
- countertop 1
- drawer 3
- drawer 2
- drawer 1
- fridge 1
- garbagecan 1
- microwave 1
- shelf 3
- shelf 2
- shelf 1
- sinkbasin 1
- stoveburner 4
- stoveburner 3
- stoveburner 2
- stoveburner 1
- toaster 1

Your task is to: put a clean knife on countertop.

Interaction:

1. think: To solve the task, I need to find and take a clean knife, then put it on countertop.
2. go to countertop 1
3. take knife 1 from countertop 2
4. put knife 1 in/on countertop 1
---
#

# ReAct: Synergizing Reasoning and Acting in Language Models

# ReAct: Synergizing Reasoning and Acting in Language Models

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Table 10: Example trajectories for Webshop predicted by Act and ReAct

Compared to Act, ReAct uses reasoning to find products that satisfy all target attributes.

|Instruction|Act|ReAct|
|---|---|---|
|get me a sixteen pack of apple cinnamon freeze dried banana chips, and price lower than 50.00 dollars|Action: search[sixteen pack apple cinnamon freeze dried banana chips] Observation: [ Back to Search ] Page 1 (Total results: 50) [Next] [B0061IVFZE] ...|Action: search[sixteen pack apple cinnamon freeze dried banana chips] Observation: [ Back to Search ] Page 1 (Total results: 50) [Next] [B0061IVFZE] ...|
| |...|...|

Score: 0.125 (Act) - Score: 1.0 (ReAct)
---
#

# ReAct: Synergizing Reasoning and Acting in Language Models

# ReAct: Synergizing Reasoning and Acting in Language Models

Published as a conference paper at ICLR 2023

# More Analysis

# Success and Failure Modes Analysis

We provide some examples corresponding to the success and error mode analysis given in Sec. 3.3. Search results and non-representative steps are omitted to reduce space.

# Success: True positive

|Model|Question|Thought|Action|Observation|
|---|---|---|---|---|
|ReAct|Author David Chanoff collaboration|I need to search David Chanoff...|Search[David Chanoff]|David Chanoff is a noted author...|
|ReAct|William J. Crowe collaboration|William J. Crowe served as...|Finish[Bill Clinton]|Episode finished|

# Success: False positive

|Model|Question|Thought|Action|Observation|
|---|---|---|---|---|
|ReAct|Board game release order|I need to search San Marco...|Search[San Marco]|San Marco is one of the...|
|ReAct|University founding order|Vanderbilt University was founded...|Answer: Emory University| |

# Failure: Reasoning error

|Model|Question|Thought|Action|Observation|
|---|---|---|---|---|
|ReAct|Actress middle name|I need to search Harvey Fierstein...|Search[Harvey Fierstein]|Harvey Forbes Fierstein...|
|CoT|Comparison of ages|Danny Green was born in 1987...|Answer: Danny Green| |
---
#

# ReAct: Synergizing Reasoning and Acting in Language Models

# ReAct: Synergizing Reasoning and Acting in Language Models

We have proposed ReAct - a simple yet effective method for synergizing reasoning and acting in large language models. Through a diverse set of experiments on multi-hop question-answering, fact checking, and interactive decision-making tasks.

# Failure: Search error

|Question|What does the goddess associated with the goddess Frigg consist of in what tales?|
|---|---|
|Thought 1|I need to search goddess Frigg and find its associated goddess.|
|Action 1|Search[goddess Frigg]|
|Observation 1|Could not find goddess Frigg. Similar: ['Frigg', 'Frigg and Freyja common origin hypothesis', 'Freyja (section Relation to Frigg and other goddesses and figures)', 'Eir (redirect from Eir (goddess))', 'Baldr'].|
|Thought 2|I need to search Frigg instead...|

# Failure: Hallucination

|Question|What was the first year a scientific journal published by an organization located in the Bronx was published?|
|---|---|
|Thought|Let’s think step by step. The first year a scientific journal published by an organization located in the Bronx was published was 1916.|
|Answer|1916 (Label: 1909)|

# Failure: Label ambiguity

|Question|What nationality is the man who developed the dictator game?|
|---|---|
|Thought 1|I need to search dictator game, find the man who developed it, then find his nationality.|
|Action 1|Search[dictator game]|
|Observation 1|The dictator game is a popular experimental instrument in social psychology and economics...|
|Action 3|Search[Amos Tversky]|
|Observation 3|Amos Nathan Tversky...|
|Thought 4|Amos Tversky is an Israeli cognitive and mathematical psychologist. So the man who developed the dictator game is Israeli.|
|Action 4|Finish[Israeli] (label: Israel-American)|

# CoT

|Question|Kurt Fuller from Stockton, CA appeared in which American Detective Comedy Drama television series created by Steve Franks?|
|---|---|
|Thought|Let’s think step by step. Kurt Fuller from Stockton, CA appeared in Psych. Psych is an American Detective Comedy Drama television series created by Steve Franks.|
|Answer|Psych (label: Psych is an American detective comedy-drama)|
